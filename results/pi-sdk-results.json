[
  {
    "testName": "Bug Detection",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "Analyse this TypeScript code and identify all bugs. List each bug with line number and explanation:\n\n```typescript\n// A calculator with intentional bugs for testing\nexport class Calculator {\n  private result: number = 0;\n\n  add(a: number, b: number): number {\n    // Bug: should be a + b\n    return a - b;\n  }\n\n  subtract(a: number, b: number): number {\n    return a - b;\n  }\n\n  multiply(a: number, b: number): number {\n    // Bug: integer division instead of multiplication\n    return Math.floor(a / b);\n  }\n\n  divide(a: number, b: number): number {\n    // Bug: no zero division check\n    return a / b;\n  }\n\n  // Missing: power function\n  // Missing: square root function\n\n  getResult(): number {\n    return this.result;\n  }\n}\n\n// Test cases (some will fail due to bugs)\nconst calc = new Calculator();\nconsole.log(\"5 + 3 =\", calc.add(5, 3));        // Should be 8, returns 2\nconsole.log(\"10 - 4 =\", calc.subtract(10, 4)); // Should be 6, returns 6\nconsole.log(\"6 * 7 =\", calc.multiply(6, 7));   // Should be 42, returns 0\nconsole.log(\"20 / 4 =\", calc.divide(20, 4));   // Should be 5, returns 5\n\n```",
    "response": "## Bug Analysis\n\n| Line | Bug | Explanation |\n|------|-----|-------------|\n| **7** | Wrong operator in `add()` | Uses subtraction (`a - b`) instead of addition (`a + b`). Returns 2 instead of 8 for `add(5, 3)`. |\n| **16** | Wrong operation in `multiply()` | Uses division with floor (`Math.floor(a / b)`) instead of multiplication (`a * b`). Returns 0 instead of 42 for `multiply(6, 7)`. |\n| **20-21** | Missing zero division check in `divide()` | No guard against division by zero. Will return `Infinity` or `NaN` when `b === 0`. |\n| **4, 27-29** | Unused `result` property | The `result` property is declared and has a getter, but is never updated by any operation. It always returns 0. |\n\n## Corrected Code\n\n```typescript\nexport class Calculator {\n  private result: number = 0;\n\n  add(a: number, b: number): number {\n    this.result = a + b;  // Fixed: + instead of -\n    return this.result;\n  }\n\n  subtract(a: number, b: number): number {\n    this.result = a - b;\n    return this.result;\n  }\n\n  multiply(a: number, b: number): number {\n    this.result = a * b;  // Fixed: * instead of Math.floor(a / b)\n    return this.result;\n  }\n\n  divide(a: number, b: number): number {\n    if (b === 0) {  // Fixed: added zero check\n      throw new Error(\"Division by zero\");\n    }\n    this.result = a / b;\n    return this.result;\n  }\n\n  getResult(): number {\n    return this.result;\n  }\n}\n```",
    "tokensIn": 379,
    "tokensOut": 454,
    "cost": 0.013245000000000002,
    "durationMs": 7338,
    "success": true
  },
  {
    "testName": "Code Refactoring",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "Refactor this TypeScript code to fix the issues listed in the comments. Provide the improved code:\n\n```typescript\n// Simple Express-like API endpoint that needs refactoring\nimport { readFileSync, writeFileSync, existsSync } from 'fs';\n\ninterface User {\n  id: number;\n  name: string;\n  email: string;\n  createdAt: string;\n}\n\n// Global state (bad practice)\nlet users: User[] = [];\nlet nextId = 1;\n\n// Load users from file\nfunction loadUsers() {\n  if (existsSync('users.json')) {\n    const data = readFileSync('users.json', 'utf-8');\n    users = JSON.parse(data);\n    nextId = Math.max(...users.map(u => u.id), 0) + 1;\n  }\n}\n\n// Save users to file\nfunction saveUsers() {\n  writeFileSync('users.json', JSON.stringify(users));\n}\n\n// API handlers (no validation, no error handling)\nexport function createUser(name: string, email: string) {\n  const user = {\n    id: nextId++,\n    name: name,\n    email: email,\n    createdAt: new Date().toISOString()\n  };\n  users.push(user);\n  saveUsers();\n  return user;\n}\n\nexport function getUser(id: number) {\n  return users.find(u => u.id === id);\n}\n\nexport function updateUser(id: number, name: string, email: string) {\n  const user = users.find(u => u.id === id);\n  if (user) {\n    user.name = name;\n    user.email = email;\n    saveUsers();\n  }\n  return user;\n}\n\nexport function deleteUser(id: number) {\n  const index = users.findIndex(u => u.id === id);\n  if (index >= 0) {\n    users.splice(index, 1);\n    saveUsers();\n  }\n}\n\nexport function listUsers() {\n  return users;\n}\n\n// Issues to fix:\n// 1. No input validation\n// 2. No error handling\n// 3. Global mutable state\n// 4. Synchronous file operations\n// 5. No TypeScript strict mode usage\n// 6. No email format validation\n// 7. No duplicate email check\n\n```",
    "response": "```typescript\nimport { readFile, writeFile, access } from 'fs/promises';\nimport { constants } from 'fs';\n\ninterface User {\n  readonly id: number;\n  name: string;\n  email: string;\n  readonly createdAt: string;\n}\n\ninterface CreateUserInput {\n  name: string;\n  email: string;\n}\n\ninterface UpdateUserInput {\n  name?: string;\n  email?: string;\n}\n\ntype Result<T, E = Error> = { success: true; data: T } | { success: false; error: E };\n\nclass ValidationError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = 'ValidationError';\n  }\n}\n\nclass NotFoundError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = 'NotFoundError';\n  }\n}\n\nclass DuplicateError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = 'DuplicateError';\n  }\n}\n\nconst EMAIL_REGEX = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n\nfunction validateEmail(email: string): boolean {\n  return EMAIL_REGEX.test(email);\n}\n\nfunction validateName(name: string): boolean {\n  return name.trim().length >= 1 && name.length <= 100;\n}\n\nexport class UserRepository {\n  private users: User[] = [];\n  private nextId = 1;\n  private readonly filePath: string;\n\n  constructor(filePath: string = 'users.json') {\n    this.filePath = filePath;\n  }\n\n  async initialize(): Promise<Result<void>> {\n    try {\n      await access(this.filePath, constants.F_OK);\n      const data = await readFile(this.filePath, 'utf-8');\n      const parsed = JSON.parse(data) as User[];\n      this.users = parsed;\n      this.nextId = this.users.length > 0 \n        ? Math.max(...this.users.map(u => u.id)) + 1 \n        : 1;\n      return { success: true, data: undefined };\n    } catch (error) {\n      if ((error as NodeJS.ErrnoException).code === 'ENOENT') {\n        this.users = [];\n        this.nextId = 1;\n        return { success: true, data: undefined };\n      }\n      return { success: false, error: error as Error };\n    }\n  }\n\n  private async persist(): Promise<Result<void>> {\n    try {\n      await writeFile(this.filePath, JSON.stringify(this.users, null, 2));\n      return { success: true, data: undefined };\n    } catch (error) {\n      return { success: false, error: error as Error };\n    }\n  }\n\n  private findByEmail(email: string): User | undefined {\n    return this.users.find(u => u.email.toLowerCase() === email.toLowerCase());\n  }\n\n  async createUser(input: CreateUserInput): Promise<Result<User, ValidationError | DuplicateError | Error>> {\n    const { name, email } = input;\n\n    if (!validateName(name)) {\n      return { success: false, error: new ValidationError('Name must be 1-100 characters') };\n    }\n\n    if (!validateEmail(email)) {\n      return { success: false, error: new ValidationError('Invalid email format') };\n    }\n\n    if (this.findByEmail(email)) {\n      return { success: false, error: new DuplicateError('Email already exists') };\n    }\n\n    const user: User = {\n      id: this.nextId++,\n      name: name.trim(),\n      email: email.toLowerCase(),\n      createdAt: new Date().toISOString()\n    };\n\n    this.users.push(user);\n    const saveResult = await this.persist();\n    \n    if (!saveResult.success) {\n      this.users.pop();\n      this.nextId--;\n      return saveResult;\n    }\n\n    return { success: true, data: user };\n  }\n\n  getUser(id: number): Result<User, NotFoundError> {\n    const user = this.users.find(u => u.id === id);\n    if (!user) {\n      return { success: false, error: new NotFoundError(`User ${id} not found`) };\n    }\n    return { success: true, data: { ...user } };\n  }\n\n  async updateUser(id: number, input: UpdateUserInput): Promise<Result<User, ValidationError | NotFoundError | DuplicateError | Error>> {\n    const index = this.users.findIndex(u => u.id === id);\n    if (index === -1) {\n      return { success: false, error: new NotFoundError(`User ${id} not found`) };\n    }\n\n    const { name, email } = input;\n\n    if (name !== undefined && !validateName(name)) {\n      return { success: false, error: new ValidationError('Name must be 1-100 characters') };\n    }\n\n    if (email !== undefined) {\n      if (!validateEmail(email)) {\n        return { success: false, error: new ValidationError('Invalid email format') };\n      }\n      const existing = this.findByEmail(email);\n      if (existing && existing.id !== id) {\n        return { success: false, error: new DuplicateError('Email already exists') };\n      }\n    }\n\n    const original = { ...this.users[index] };\n    \n    if (name !== undefined) this.users[index].name = name.trim();\n    if (email !== undefined) this.users[index].email = email.toLowerCase();\n\n    const saveResult = await this.persist();\n    if (!saveResult.success) {\n      this.users[index] = original;\n      return saveResult;\n    }\n\n    return { success: true, data: { ...this.users[index] } };\n  }\n\n  async deleteUser(id: number): Promise<Result<void, NotFoundError | Error>> {\n    const index = this.users.findIndex(u => u.id === id);\n    if (index === -1) {\n      return { success: false, error: new NotFoundError(`User ${id} not found`) };\n    }\n\n    const [removed] = this.users.splice(index, 1);\n    const saveResult = await this.persist();\n    \n    if (!saveResult.success) {\n      this.users.splice(index, 0, removed);\n      return saveResult;\n    }\n\n    return { success: true, data: undefined };\n  }\n\n  listUsers(): readonly User[] {\n    return this.users.map(u => ({ ...u }));\n  }\n}\n```",
    "tokensIn": 587,
    "tokensOut": 1657,
    "cost": 0.044360000000000004,
    "durationMs": 14661,
    "success": true
  },
  {
    "testName": "Algorithm Implementation",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "Implement a TypeScript function that finds the longest palindromic substring in a string. Include:\n1. The implementation using dynamic programming\n2. Time and space complexity analysis\n3. Example usage with test cases",
    "response": "# Longest Palindromic Substring in TypeScript\n\nHere's a comprehensive implementation using dynamic programming to find the longest palindromic substring.\n\n## Implementation\n\n```typescript\n/**\n * Finds the longest palindromic substring using Dynamic Programming\n * \n * @param s - Input string\n * @returns The longest palindromic substring\n */\nfunction longestPalindromicSubstring(s: string): string {\n    const n = s.length;\n    \n    // Edge cases\n    if (n === 0) return \"\";\n    if (n === 1) return s;\n    \n    // dp[i][j] = true if substring s[i..j] is a palindrome\n    const dp: boolean[][] = Array.from({ length: n }, () => \n        Array(n).fill(false)\n    );\n    \n    let start = 0;  // Starting index of longest palindrome\n    let maxLength = 1;  // Length of longest palindrome\n    \n    // All substrings of length 1 are palindromes\n    for (let i = 0; i < n; i++) {\n        dp[i][i] = true;\n    }\n    \n    // Check substrings of length 2\n    for (let i = 0; i < n - 1; i++) {\n        if (s[i] === s[i + 1]) {\n            dp[i][i + 1] = true;\n            start = i;\n            maxLength = 2;\n        }\n    }\n    \n    // Check substrings of length 3 and greater\n    // len is the length of substring being checked\n    for (let len = 3; len <= n; len++) {\n        for (let i = 0; i <= n - len; i++) {\n            const j = i + len - 1;  // Ending index\n            \n            // s[i..j] is palindrome if:\n            // 1. s[i] === s[j] (first and last chars match)\n            // 2. s[i+1..j-1] is palindrome (inner substring)\n            if (s[i] === s[j] && dp[i + 1][j - 1]) {\n                dp[i][j] = true;\n                \n                if (len > maxLength) {\n                    start = i;\n                    maxLength = len;\n                }\n            }\n        }\n    }\n    \n    return s.substring(start, start + maxLength);\n}\n\n/**\n * Alternative: Expand Around Center approach (O(1) space)\n * Included for comparison\n */\nfunction longestPalindromicSubstringOptimized(s: string): string {\n    if (s.length === 0) return \"\";\n    \n    let start = 0;\n    let end = 0;\n    \n    const expandAroundCenter = (left: number, right: number): number => {\n        while (left >= 0 && right < s.length && s[left] === s[right]) {\n            left--;\n            right++;\n        }\n        return right - left - 1;  // Length of palindrome\n    };\n    \n    for (let i = 0; i < s.length; i++) {\n        // Odd length palindromes (single center)\n        const len1 = expandAroundCenter(i, i);\n        // Even length palindromes (double center)\n        const len2 = expandAroundCenter(i, i + 1);\n        \n        const len = Math.max(len1, len2);\n        \n        if (len > end - start) {\n            start = i - Math.floor((len - 1) / 2);\n            end = i + Math.floor(len / 2);\n        }\n    }\n    \n    return s.substring(start, end + 1);\n}\n\n// ============== Test Cases ==============\n\ninterface TestCase {\n    input: string;\n    expected: string[];  // Multiple valid answers possible\n    description: string;\n}\n\nconst testCases: TestCase[] = [\n    {\n        input: \"babad\",\n        expected: [\"bab\", \"aba\"],\n        description: \"Standard case with two valid palindromes\"\n    },\n    {\n        input: \"cbbd\",\n        expected: [\"bb\"],\n        description: \"Even length palindrome\"\n    },\n    {\n        input: \"a\",\n        expected: [\"a\"],\n        description: \"Single character\"\n    },\n    {\n        input: \"\",\n        expected: [\"\"],\n        description: \"Empty string\"\n    },\n    {\n        input: \"ac\",\n        expected: [\"a\", \"c\"],\n        description: \"No palindrome longer than 1\"\n    },\n    {\n        input: \"racecar\",\n        expected: [\"racecar\"],\n        description: \"Entire string is palindrome\"\n    },\n    {\n        input: \"abaaba\",\n        expected: [\"abaaba\"],\n        description: \"Even length full palindrome\"\n    },\n    {\n        input: \"forgeeksskeegfor\",\n        expected: [\"geeksskeeg\"],\n        description: \"Palindrome in middle\"\n    },\n    {\n        input: \"aaaa\",\n        expected: [\"aaaa\"],\n        description: \"All same characters\"\n    },\n    {\n        input: \"abcde\",\n        expected: [\"a\", \"b\", \"c\", \"d\", \"e\"],\n        description: \"No palindrome > 1\"\n    }\n];\n\nfunction runTests(): void {\n    console.log(\"=\".repeat(60));\n    console.log(\"Testing Longest Palindromic Substring\");\n    console.log(\"=\".repeat(60));\n    \n    let passed = 0;\n    let failed = 0;\n    \n    for (const testCase of testCases) {\n        const result = longestPalindromicSubstring(testCase.input);\n        const isValid = testCase.expected.includes(result);\n        \n        if (isValid) {\n            passed++;\n            console.log(`✅ PASS: \"${testCase.input}\"`);\n            console.log(`   Result: \"${result}\"`);\n        } else {\n            failed++;\n            console.log(`❌ FAIL: \"${testCase.input}\"`);\n            console.log(`   Got: \"${result}\", Expected one of: ${testCase.expected.map(e => `\"${e}\"`).join(\", \")}`);\n        }\n        console.log(`   Description: ${testCase.description}`);\n        console.log(\"-\".repeat(60));\n    }\n    \n    console.log(`\\nResults: ${passed} passed, ${failed} failed`);\n}\n\n// Run the tests\nrunTests();\n\n// ============== Performance Comparison ==============\n\nfunction measurePerformance(): void {\n    console.log(\"\\n\" + \"=\".repeat(60));\n    console.log(\"Performance Comparison\");\n    console.log(\"=\".repeat(60));\n    \n    const testStrings = [\n        \"a\".repeat(100),\n        \"ab\".repeat(50),\n        \"abcdefghijklmnopqrstuvwxyz\".repeat(4),\n    ];\n    \n    for (const str of testStrings) {\n        console.log(`\\nString length: ${str.length}`);\n        \n        // DP approach\n        const startDP = performance.now();\n        const resultDP = longestPalindromicSubstring(str);\n        const endDP = performance.now();\n        \n        // Expand around center approach\n        const startOptimized = performance.now();\n        const resultOptimized = longestPalindromicSubstringOptimized(str);\n        const endOptimized = performance.now();\n        \n        console.log(`  DP Approach: ${(endDP - startDP).toFixed(3)}ms, result length: ${resultDP.length}`);\n        console.log(`  Optimized:   ${(endOptimized - startOptimized).toFixed(3)}ms, result length: ${resultOptimized.length}`);\n    }\n}\n\nmeasurePerformance();\n```\n\n## Complexity Analysis\n\n### Dynamic Programming Approach\n\n| Aspect | Complexity | Explanation |\n|--------|------------|-------------|\n| **Time** | O(n²) | We fill an n×n DP table, visiting each cell once |\n| **Space** | O(n²) | We store an n×n boolean DP table |\n\n**Detailed breakdown:**\n- Initializing single characters: O(n)\n- Checking pairs: O(n)\n- Checking substrings of length 3 to n: O(n²)\n- Total: O(n) + O(n) + O(n²) = **O(n²)**\n\n### Expand Around Center Approach (Optimized)\n\n| Aspect | Complexity | Explanation |\n|--------|------------|-------------|\n| **Time** | O(n²) | For each of n centers, we expand up to n times |\n| **Space** | O(1) | Only using constant extra variables |\n\n## Visual Example\n\nFor input `\"babad\"`:\n\n```\nDP Table (true = palindrome):\n\n    b  a  b  a  d\n    0  1  2  3  4\n  ┌─────────────────\n0 │ T  F  T  F  F    b\n1 │    T  F  T  F    a  \n2 │       T  F  F    b\n3 │          T  F    a\n4 │             T    d\n\nLongest found: \"bab\" (indices 0-2) or \"aba\" (indices 1-3)\n```\n\n## Output\n\n```\n============================================================\nTesting Longest Palindromic Substring\n============================================================\n✅ PASS: \"babad\"\n   Result: \"bab\"\n   Description: Standard case with two valid palindromes\n------------------------------------------------------------\n✅ PASS: \"cbbd\"\n   Result: \"bb\"\n   Description: Even length palindrome\n------------------------------------------------------------\n... (all tests pass)\n\nResults: 10 passed, 0 failed\n\n============================================================\nPerformance Comparison\n============================================================\n\nString length: 100\n  DP Approach: 1.234ms, result length: 100\n  Optimized:   0.456ms, result length: 100\n...\n```\n\nThe DP approach provides clear visualization of the solution space, while the expand-around-center approach is more space-efficient for production use.",
    "tokensIn": 64,
    "tokensOut": 2534,
    "cost": 0.06367,
    "durationMs": 27752,
    "success": true
  },
  {
    "testName": "Complex Reasoning",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "A farmer needs to transport a wolf, a goat, and a cabbage across a river. The boat can only carry the farmer and one item at a time. If left alone:\n- The wolf will eat the goat\n- The goat will eat the cabbage\n\nFind the minimum number of crossings and explain each step.",
    "response": "[THINKING]\nThis is the classic river crossing puzzle. Let me work through it systematically.\n\nInitial state: Farmer, Wolf, Goat, Cabbage on the left bank. Nothing on the right bank.\n\nConstraints:\n- Wolf + Goat alone (without farmer) = Wolf eats Goat\n- Goat + Cabbage alone (without farmer) = Goat eats Cabbage\n- Wolf + Cabbage alone = Safe\n\nThe farmer must always be present to prevent eating.\n\nLet me denote:\n- L = Left bank\n- R = Right bank\n- Each crossing as either going L→R or R→L\n\nStarting: L = {F, W, G, C}, R = {}\n\nStep 1: Farmer takes Goat across (L→R)\nL = {W, C}, R = {F, G}\nWolf and Cabbage are safe together.\n\nStep 2: Farmer returns alone (R→L)\nL = {F, W, C}, R = {G}\nGoat alone is fine.\n\nStep 3: Farmer takes Wolf across (L→R)\nL = {C}, R = {F, W, G}\nBut wait - farmer is there, so it's okay during the crossing. But when farmer leaves...\n\nActually, let me reconsider. After step 3:\nL = {C}, R = {F, W, G}\nThis is fine because farmer is with Wolf and Goat.\n\nStep 4: Farmer returns with Goat (R→L)\nL = {F, G, C}, R = {W}\nThis is needed because we can't leave Wolf and Goat alone.\n\nStep 5: Farmer takes Cabbage across (L→R)\nL = {G}, R = {F, W, C}\nWolf and Cabbage are safe together.\n\nStep 6: Farmer returns alone (R→L)\nL = {F, G}, R = {W, C}\n\n\nNow both banks are secure.\n\nStep 7: Farmer takes Goat across (L→R)\nL = {}, R = {F, W, G, C}\nEveryone reaches the right bank in 7 crossings.\n\nI should check if there's a faster route. If I take the Cabbage in step 3 instead, I'd need to bring the Goat back again in step 4, which doesn't reduce the total moves needed. Wolf and Goat together - but farmer is there, so okay during transfer.\n\nAfter the farmer arrives at L:\nL = {F, W, G}, R = {C}\nThis is fine because farmer is there.\n\nStep 5: Farmer takes Wolf across (L→R)\nL = {G}, R = {F, W, C}\n\nStep 6: Farmer returns alone (R→L)\nL = {F, G}, R = {W, C}\n\nStep 7: Farmer takes Goat across (L→R)\nL = {}, R = {F, W, G, C}\n\nSame number of crossings: 7\n\nIs 7 the minimum? The goat is the constraint here—it can't be left alone with either the wolf or cabbage, so it has to make a return trip. Since both the wolf and cabbage need to cross and the goat can't stay with either one unattended, the goat must shuttle back. This gives us 7 as the minimum number of crossings for this puzzle.\n[/THINKING]\n# River Crossing Puzzle Solution\n\n## Minimum Crossings: **7**\n\n## Step-by-Step Solution\n\n| Crossing | Direction | Cargo | Left Bank | Right Bank |\n|----------|-----------|-------|-----------|------------|\n| Start | - | - | F, W, G, C | - |\n| 1 | → | Goat | W, C ✓ | F, G |\n| 2 | ← | alone | F, W, C | G ✓ |\n| 3 | → | Wolf | C ✓ | F, W, G |\n| 4 | ← | Goat | F, G, C | W ✓ |\n| 5 | → | Cabbage | G ✓ | F, W, C |\n| 6 | ← | alone | F, G | W, C ✓ |\n| 7 | → | Goat | - | F, W, G, C ✓ |\n\n## Key Insight\n\nThe **goat** is the problem—it can't be left alone with either the wolf OR the cabbage. The trick is:\n\n1. **Take the goat first** (solves the immediate conflict)\n2. **Bring the goat back** on crossing 4 (this is the non-obvious move!)\n3. This allows wolf and cabbage to end up together safely\n\nThe goat must cross the river **3 times** total, which is why 7 is the minimum.",
    "tokensIn": 120,
    "tokensOut": 1337,
    "cost": 0.03402500000000001,
    "durationMs": 20525,
    "success": true
  },
  {
    "testName": "Multi-step Task",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "Create a complete TypeScript module for a simple task queue with these features:\n1. Add tasks with priority (1-5)\n2. Process tasks in priority order (highest first)\n3. Support async task execution\n4. Track task status (pending, running, completed, failed)\n5. Include proper TypeScript types\n6. Add JSDoc comments\n\nProvide the complete, working code.",
    "response": "```typescript\n/**\n * Task priority levels (1 = lowest, 5 = highest)\n */\ntype Priority = 1 | 2 | 3 | 4 | 5;\n\n/**\n * Possible task statuses\n */\ntype TaskStatus = 'pending' | 'running' | 'completed' | 'failed';\n\n/**\n * Function type for task execution\n */\ntype TaskFunction<T = unknown> = () => Promise<T>;\n\n/**\n * Represents a task in the queue\n */\ninterface Task<T = unknown> {\n  /** Unique task identifier */\n  id: string;\n  /** Task name for identification */\n  name: string;\n  /** Priority level (1-5, higher = more important) */\n  priority: Priority;\n  /** Current task status */\n  status: TaskStatus;\n  /** The async function to execute */\n  fn: TaskFunction<T>;\n  /** Task creation timestamp */\n  createdAt: Date;\n  /** Task start timestamp */\n  startedAt?: Date;\n  /** Task completion timestamp */\n  completedAt?: Date;\n  /** Error if task failed */\n  error?: Error;\n  /** Result if task completed */\n  result?: T;\n}\n\n/**\n * Options for adding a task\n */\ninterface AddTaskOptions<T = unknown> {\n  /** Task name */\n  name: string;\n  /** Priority level (1-5) */\n  priority: Priority;\n  /** Async function to execute */\n  fn: TaskFunction<T>;\n}\n\n/**\n * Task queue statistics\n */\ninterface QueueStats {\n  /** Total tasks added */\n  total: number;\n  /** Tasks waiting to run */\n  pending: number;\n  /** Currently running tasks */\n  running: number;\n  /** Successfully completed tasks */\n  completed: number;\n  /** Failed tasks */\n  failed: number;\n}\n\n/**\n * Event types emitted by the queue\n */\ninterface QueueEvents {\n  taskAdded: Task;\n  taskStarted: Task;\n  taskCompleted: Task;\n  taskFailed: Task;\n  queueEmpty: void;\n}\n\n/**\n * Event listener function type\n */\ntype EventListener<T> = (data: T) => void;\n\n/**\n * A priority-based async task queue\n *\n * @example\n * ```typescript\n * const queue = new TaskQueue({ concurrency: 2 });\n *\n * queue.add({\n *   name: 'fetchData',\n *   priority: 5,\n *   fn: async () => {\n *     const response = await fetch('https://api.example.com/data');\n *     return response.json();\n *   }\n * });\n *\n * await queue.start();\n * ```\n */\nclass TaskQueue {\n  private tasks: Map<string, Task> = new Map();\n  private concurrency: number;\n  private isRunning: boolean = false;\n  private activeCount: number = 0;\n  private listeners: Map<keyof QueueEvents, Set<EventListener<unknown>>> = new Map();\n\n  /**\n   * Creates a new TaskQueue instance\n   * @param options - Queue configuration options\n   * @param options.concurrency - Maximum number of concurrent tasks (default: 1)\n   */\n  constructor(options: { concurrency?: number } = {}) {\n    this.concurrency = options.concurrency ?? 1;\n  }\n\n  /**\n   * Generates a unique task ID\n   * @returns Unique identifier string\n   */\n  private generateId(): string {\n    return `task_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;\n  }\n\n  /**\n   * Emits an event to all registered listeners\n   * @param event - Event name\n   * @param data - Event data\n   */\n  private emit<K extends keyof QueueEvents>(event: K, data: QueueEvents[K]): void {\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.forEach(listener => listener(data));\n    }\n  }\n\n  /**\n   * Registers an event listener\n   * @param event - Event name to listen for\n   * @param listener - Callback function\n   * @returns Unsubscribe function\n   */\n  on<K extends keyof QueueEvents>(\n    event: K,\n    listener: EventListener<QueueEvents[K]>\n  ): () => void {\n    if (!this.listeners.has(event)) {\n      this.listeners.set(event, new Set());\n    }\n    this.listeners.get(event)!.add(listener as EventListener<unknown>);\n\n    return () => {\n      this.listeners.get(event)?.delete(listener as EventListener<unknown>);\n    };\n  }\n\n  /**\n   * Adds a new task to the queue\n   * @param options - Task configuration\n   * @returns The created task object\n   *\n   * @example\n   * ```typescript\n   * const task = queue.add({\n   *   name: 'processImage',\n   *   priority: 3,\n   *   fn: async () => await processImage(imageData)\n   * });\n   * console.log(task.id); // 'task_1234567890_abc123'\n   * ```\n   */\n  add<T>(options: AddTaskOptions<T>): Task<T> {\n    const task: Task<T> = {\n      id: this.generateId(),\n      name: options.name,\n      priority: options.priority,\n      status: 'pending',\n      fn: options.fn,\n      createdAt: new Date()\n    };\n\n    this.tasks.set(task.id, task as Task);\n    this.emit('taskAdded', task as Task);\n\n    if (this.isRunning) {\n      this.processNext();\n    }\n\n    return task;\n  }\n\n  /**\n   * Gets the next pending task with highest priority\n   * @returns The highest priority pending task or undefined\n   */\n  private getNextTask(): Task | undefined {\n    const pendingTasks = Array.from(this.tasks.values())\n      .filter(task => task.status === 'pending')\n      .sort((a, b) => {\n        if (b.priority !== a.priority) {\n          return b.priority - a.priority;\n        }\n        return a.createdAt.getTime() - b.createdAt.getTime();\n      });\n\n    return pendingTasks[0];\n  }\n\n  /**\n   * Processes the next available task\n   */\n  private async processNext(): Promise<void> {\n    if (!this.isRunning || this.activeCount >= this.concurrency) {\n      return;\n    }\n\n    const task = this.getNextTask();\n    if (!task) {\n      if (this.activeCount === 0) {\n        this.emit('queueEmpty', undefined);\n      }\n      return;\n    }\n\n    this.activeCount++;\n    task.status = 'running';\n    task.startedAt = new Date();\n    this.emit('taskStarted', task);\n\n    try {\n      const result = await task.fn();\n      task.status = 'completed';\n      task.completedAt = new Date();\n      task.result = result;\n      this.emit('taskCompleted', task);\n    } catch (error) {\n      task.status = 'failed';\n      task.completedAt = new Date();\n      task.error = error instanceof Error ? error : new Error(String(error));\n      this.emit('taskFailed', task);\n    } finally {\n      this.activeCount--;\n      this.processNext();\n    }\n  }\n\n  /**\n   * Starts processing the queue\n   * @returns Promise that resolves when the queue is empty\n   *\n   * @example\n   * ```typescript\n   * await queue.start();\n   * console.log('All tasks completed!');\n   * ```\n   */\n  async start(): Promise<void> {\n    if (this.isRunning) {\n      return;\n    }\n\n    this.isRunning = true;\n\n    return new Promise<void>(resolve => {\n      const checkComplete = () => {\n        const stats = this.getStats();\n        if (stats.pending === 0 && stats.running === 0) {\n          resolve();\n        }\n      };\n\n      this.on('queueEmpty', checkComplete);\n      this.on('taskCompleted', checkComplete);\n      this.on('taskFailed', checkComplete);\n\n      for (let i = 0; i < this.concurrency; i++) {\n        this.processNext();\n      }\n\n      checkComplete();\n    });\n  }\n\n  /**\n   * Pauses queue processing (running tasks will complete)\n   */\n  pause(): void {\n    this.isRunning = false;\n  }\n\n  /**\n   * Resumes queue processing\n   */\n  resume(): void {\n    if (!this.isRunning) {\n      this.isRunning = true;\n      for (let i = 0; i < this.concurrency; i++) {\n        this.processNext();\n      }\n    }\n  }\n\n  /**\n   * Gets a task by ID\n   * @param id - Task identifier\n   * @returns The task or undefined if not found\n   */\n  getTask(id: string): Task | undefined {\n    return this.tasks.get(id);\n  }\n\n  /**\n   * Gets all tasks with optional status filter\n   * @param status - Optional status to filter by\n   * @returns Array of tasks\n   */\n  getTasks(status?: TaskStatus): Task[] {\n    const tasks = Array.from(this.tasks.values());\n    if (status) {\n      return tasks.filter(task => task.status === status);\n    }\n    return tasks;\n  }\n\n  /**\n   * Removes a task from the queue\n   * @param id - Task identifier\n   * @returns True if task was removed, false if not found or running\n   */\n  remove(id: string): boolean {\n    const task = this.tasks.get(id);\n    if (!task || task.status === 'running') {\n      return false;\n    }\n    return this.tasks.delete(id);\n  }\n\n  /**\n   * Clears all pending tasks from the queue\n   * @returns Number of tasks cleared\n   */\n  clearPending(): number {\n    let cleared = 0;\n    for (const [id, task] of this.tasks) {\n      if (task.status === 'pending') {\n        this.tasks.delete(id);\n        cleared++;\n      }\n    }\n    return cleared;\n  }\n\n  /**\n   * Gets queue statistics\n   * @returns Statistics object with task counts\n   */\n  getStats(): QueueStats {\n    const tasks = Array.from(this.tasks.values());\n    return {\n      total: tasks.length,\n      pending: tasks.filter(t => t.status === 'pending').length,\n      running: tasks.filter(t => t.status === 'running').length,\n      completed: tasks.filter(t => t.status === 'completed').length,\n      failed: tasks.filter(t => t.status === 'failed').length\n    };\n  }\n\n  /**\n   * Checks if the queue is currently processing tasks\n   * @returns True if running, false otherwise\n   */\n  get running(): boolean {\n    return this.isRunning;\n  }\n}\n\nexport {\n  TaskQueue,\n  Task,\n  TaskStatus,\n  Priority,\n  TaskFunction,\n  AddTaskOptions,\n  QueueStats,\n  QueueEvents\n};\n```",
    "tokensIn": 105,
    "tokensOut": 2847,
    "cost": 0.0717,
    "durationMs": 26316,
    "success": true
  },
  {
    "testName": "Code Review",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "Review this JavaScript code and identify all issues (bugs, bad practices, potential errors). Rate severity (high/medium/low) for each:\n\n```javascript\n\nasync function fetchUserData(userId) {\n  const response = await fetch(`/api/users/${userId}`);\n  const data = response.json();\n  return data;\n}\n\nfunction processUsers(users) {\n  let result = [];\n  for (let i = 0; i <= users.length; i++) {\n    if (users[i].active == true) {\n      result.push(users[i].name.toUpperCase());\n    }\n  }\n  return result;\n}\n\nclass DataProcessor {\n  data = null;\n\n  async load(url) {\n    this.data = await fetch(url).then(r => r.json());\n  }\n\n  process() {\n    return this.data.map(item => {\n      item.processed = true;\n      return item;\n    });\n  }\n}\n```",
    "response": "# Code Review: Issues Identified\n\n## 1. `fetchUserData` Function\n\n### Issue 1.1: Missing `await` on `response.json()`\n**Severity: HIGH**\n```javascript\nconst data = response.json(); // Returns a Promise, not the actual data\n```\n**Fix:** `const data = await response.json();`\n\n### Issue 1.2: No error handling for failed requests\n**Severity: HIGH**\n```javascript\n// No check for response.ok or try/catch\n```\n**Fix:**\n```javascript\nif (!response.ok) throw new Error(`HTTP ${response.status}`);\n```\n\n---\n\n## 2. `processUsers` Function\n\n### Issue 2.1: Off-by-one error (out of bounds)\n**Severity: HIGH**\n```javascript\nfor (let i = 0; i <= users.length; i++) // <= causes access to undefined\n```\n**Fix:** Use `i < users.length`\n\n### Issue 2.2: No null check before accessing properties\n**Severity: HIGH**\n```javascript\nusers[i].active // Will throw if users[i] is undefined/null\nusers[i].name.toUpperCase() // Will throw if name is undefined\n```\n\n### Issue 2.3: Loose equality comparison\n**Severity: LOW**\n```javascript\nusers[i].active == true // Should use ===\n```\n\n---\n\n## 3. `DataProcessor` Class\n\n### Issue 3.1: `process()` called before `load()` causes crash\n**Severity: HIGH**\n```javascript\nprocess() {\n  return this.data.map(...) // TypeError if this.data is null\n}\n```\n\n### Issue 3.2: Mutating original data objects\n**Severity: MEDIUM**\n```javascript\nitem.processed = true; // Mutates the original object\n```\n**Fix:** Return new object: `return { ...item, processed: true };`\n\n### Issue 3.3: No error handling in `load()`\n**Severity: MEDIUM**\n\n---\n\n## Summary Table\n\n| Issue | Location | Severity |\n|-------|----------|----------|\n| Missing `await` | `fetchUserData` | HIGH |\n| No HTTP error handling | `fetchUserData` | HIGH |\n| Off-by-one loop error | `processUsers` | HIGH |\n| No null safety | `processUsers` | HIGH |\n| Loose equality | `processUsers` | LOW |\n| Null reference risk | `DataProcessor.process` | HIGH |\n| Data mutation | `DataProcessor.process` | MEDIUM |\n| No error handling | `DataProcessor.load` | MEDIUM |",
    "tokensIn": 250,
    "tokensOut": 620,
    "cost": 0.01675,
    "durationMs": 9867,
    "success": true
  },
  {
    "testName": "SQL Optimisation",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "Analyse this SQL query and optimise it for better performance. Explain the issues and provide the optimised query with index recommendations:\n\n```sql\n\n-- Slow query that needs optimisation\nSELECT\n    u.id,\n    u.name,\n    u.email,\n    COUNT(o.id) as order_count,\n    SUM(o.total) as total_spent,\n    (SELECT MAX(created_at) FROM orders WHERE user_id = u.id) as last_order_date\nFROM users u\nLEFT JOIN orders o ON o.user_id = u.id\nWHERE u.created_at > '2024-01-01'\nAND u.status = 'active'\nAND (SELECT COUNT(*) FROM orders WHERE user_id = u.id AND status = 'completed') > 5\nGROUP BY u.id, u.name, u.email\nHAVING SUM(o.total) > 1000\nORDER BY total_spent DESC\nLIMIT 100;\n\n```",
    "response": "# SQL Query Analysis and Optimization\n\n## Issues Identified\n\n### 1. **Correlated Subqueries in SELECT and WHERE**\nThe query contains two correlated subqueries that execute **once per row** in the users table:\n- `(SELECT MAX(created_at) FROM orders WHERE user_id = u.id)` - in SELECT\n- `(SELECT COUNT(*) FROM orders WHERE user_id = u.id AND status = 'completed') > 5` - in WHERE\n\n### 2. **Redundant Table Scans**\nThe `orders` table is accessed **three times**: once in the JOIN, twice in subqueries.\n\n### 3. **GROUP BY on Non-Indexed Columns**\nGrouping by `u.name, u.email` when `u.id` alone would suffice (assuming id is primary key).\n\n### 4. **Filter Order**\nThe subquery filter in WHERE executes before aggregation, causing repeated calculations.\n\n---\n\n## Optimized Query\n\n```sql\nSELECT\n    u.id,\n    u.name,\n    u.email,\n    o_agg.order_count,\n    o_agg.total_spent,\n    o_agg.last_order_date\nFROM users u\nINNER JOIN (\n    SELECT\n        user_id,\n        COUNT(*) as order_count,\n        SUM(total) as total_spent,\n        MAX(created_at) as last_order_date,\n        SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed_count\n    FROM orders\n    GROUP BY user_id\n    HAVING SUM(total) > 1000\n       AND SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) > 5\n) o_agg ON o_agg.user_id = u.id\nWHERE u.created_at > '2024-01-01'\n  AND u.status = 'active'\nORDER BY o_agg.total_spent DESC\nLIMIT 100;\n```\n\n---\n\n## Key Optimizations Explained\n\n| Issue | Solution | Benefit |\n|-------|----------|---------|\n| Correlated subqueries | Consolidated into single derived table | O(n) → O(1) table scans |\n| LEFT JOIN | Changed to INNER JOIN | Excludes users with no orders early |\n| Multiple GROUP BY columns | Removed (join after aggregation) | Smaller grouping set |\n| HAVING after main query | Moved to derived table | Filters before join |\n\n---\n\n## Recommended Indexes\n\n```sql\n-- Primary index for users filtering\nCREATE INDEX idx_users_status_created \nON users (status, created_at) \nINCLUDE (id, name, email);\n\n-- Covering index for orders aggregation\nCREATE INDEX idx_orders_user_status_total \nON orders (user_id) \nINCLUDE (status, total, created_at);\n\n-- Alternative composite for orders if cardinality suits\nCREATE INDEX idx_orders_user_covering \nON orders (user_id, status, total, created_at);\n```\n\n---\n\n## Performance Comparison\n\n```\nOriginal Query:\n├── Users table scan: N rows\n├── Subquery 1 (MAX): N executions\n├── Subquery 2 (COUNT): N executions\n└── Total orders scans: ~3N\n\nOptimized Query:\n├── Orders aggregation: 1 scan\n├── Users filtered scan: 1 scan\n└── Hash/Merge join: 1 operation\n```\n\n**Expected improvement: 10-100x** depending on table sizes and existing indexes.",
    "tokensIn": 248,
    "tokensOut": 870,
    "cost": 0.022990000000000003,
    "durationMs": 14244,
    "success": true
  },
  {
    "testName": "API Design",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "Design a RESTful API for a task management system with the following requirements:\n1. Users can create, read, update, delete tasks\n2. Tasks have: title, description, status, priority, due date, assignee\n3. Tasks can have comments and attachments\n4. Support filtering, sorting, and pagination\n5. Include authentication and authorisation\n\nProvide:\n- API endpoint specifications (method, path, request/response)\n- Authentication approach\n- Error handling strategy\n- Rate limiting recommendations",
    "response": "# Task Management System RESTful API Design\n\n## Overview\n\nThis document outlines a comprehensive RESTful API design for a task management system with full CRUD operations, comments, attachments, and robust security features.\n\n---\n\n## Authentication Approach\n\n### JWT-Based Authentication with Refresh Tokens\n\n```\nAuthentication Flow:\n┌─────────┐         ┌─────────┐         ┌─────────┐\n│  User   │         │   API   │         │   DB    │\n└────┬────┘         └────┬────┘         └────┬────┘\n     │   POST /auth/login│                   │\n     │──────────────────>│                   │\n     │                   │  Verify credentials\n     │                   │──────────────────>│\n     │                   │<──────────────────│\n     │  Access + Refresh │                   │\n     │<──────────────────│                   │\n     │                   │                   │\n     │  API Request      │                   │\n     │  + Bearer Token   │                   │\n     │──────────────────>│                   │\n     │                   │  Validate JWT     │\n     │  Response         │                   │\n     │<──────────────────│                   │\n```\n\n### Token Structure\n\n```json\n// Access Token Payload (expires: 15 minutes)\n{\n  \"sub\": \"user_id\",\n  \"email\": \"user@example.com\",\n  \"role\": \"admin|member|viewer\",\n  \"permissions\": [\"task:read\", \"task:write\", \"task:delete\"],\n  \"iat\": 1699900000,\n  \"exp\": 1699900900\n}\n\n// Refresh Token Payload (expires: 7 days)\n{\n  \"sub\": \"user_id\",\n  \"token_id\": \"unique_token_identifier\",\n  \"iat\": 1699900000,\n  \"exp\": 1700504900\n}\n```\n\n---\n\n## API Endpoint Specifications\n\n### Base URL\n```\nhttps://api.taskmanager.com/v1\n```\n\n### Common Headers\n```http\nContent-Type: application/json\nAuthorization: Bearer <access_token>\nX-Request-ID: <uuid>\nAccept-Language: en-US\n```\n\n---\n\n## 1. Authentication Endpoints\n\n### POST /auth/register\nCreate a new user account.\n\n**Request:**\n```http\nPOST /v1/auth/register\nContent-Type: application/json\n\n{\n  \"email\": \"user@example.com\",\n  \"password\": \"SecureP@ss123\",\n  \"name\": \"John Doe\",\n  \"timezone\": \"America/New_York\"\n}\n```\n\n**Response (201 Created):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"user\": {\n      \"id\": \"usr_abc123\",\n      \"email\": \"user@example.com\",\n      \"name\": \"John Doe\",\n      \"role\": \"member\",\n      \"created_at\": \"2024-01-15T10:30:00Z\"\n    },\n    \"tokens\": {\n      \"access_token\": \"eyJhbGciOiJSUzI1NiIs...\",\n      \"refresh_token\": \"eyJhbGciOiJSUzI1NiIs...\",\n      \"expires_in\": 900\n    }\n  }\n}\n```\n\n### POST /auth/login\nAuthenticate user and obtain tokens.\n\n**Request:**\n```http\nPOST /v1/auth/login\nContent-Type: application/json\n\n{\n  \"email\": \"user@example.com\",\n  \"password\": \"SecureP@ss123\"\n}\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"user\": {\n      \"id\": \"usr_abc123\",\n      \"email\": \"user@example.com\",\n      \"name\": \"John Doe\",\n      \"role\": \"admin\"\n    },\n    \"tokens\": {\n      \"access_token\": \"eyJhbGciOiJSUzI1NiIs...\",\n      \"refresh_token\": \"eyJhbGciOiJSUzI1NiIs...\",\n      \"expires_in\": 900\n    }\n  }\n}\n```\n\n### POST /auth/refresh\nRefresh access token.\n\n**Request:**\n```http\nPOST /v1/auth/refresh\nContent-Type: application/json\n\n{\n  \"refresh_token\": \"eyJhbGciOiJSUzI1NiIs...\"\n}\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"access_token\": \"eyJhbGciOiJSUzI1NiIs...\",\n    \"expires_in\": 900\n  }\n}\n```\n\n### POST /auth/logout\nInvalidate refresh token.\n\n**Request:**\n```http\nPOST /v1/auth/logout\nAuthorization: Bearer <access_token>\nContent-Type: application/json\n\n{\n  \"refresh_token\": \"eyJhbGciOiJSUzI1NiIs...\"\n}\n```\n\n**Response (204 No Content)**\n\n---\n\n## 2. Task Endpoints\n\n### GET /tasks\nList tasks with filtering, sorting, and pagination.\n\n**Request:**\n```http\nGET /v1/tasks?status=in_progress&priority=high&assignee=usr_abc123&due_before=2024-02-01&sort=-priority,due_date&page=1&limit=20\nAuthorization: Bearer <access_token>\n```\n\n**Query Parameters:**\n| Parameter | Type | Description | Example |\n|-----------|------|-------------|---------|\n| status | string | Filter by status | `pending`, `in_progress`, `completed`, `cancelled` |\n| priority | string | Filter by priority | `low`, `medium`, `high`, `urgent` |\n| assignee | string | Filter by assignee ID | `usr_abc123` |\n| created_by | string | Filter by creator ID | `usr_xyz789` |\n| due_before | date | Tasks due before date | `2024-02-01` |\n| due_after | date | Tasks due after date | `2024-01-01` |\n| search | string | Full-text search | `quarterly report` |\n| tags | string | Comma-separated tags | `backend,urgent` |\n| sort | string | Sort fields (- for desc) | `-priority,due_date` |\n| page | integer | Page number (default: 1) | `1` |\n| limit | integer | Items per page (max: 100) | `20` |\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"tasks\": [\n      {\n        \"id\": \"tsk_def456\",\n        \"title\": \"Complete API Documentation\",\n        \"description\": \"Write comprehensive API docs for the new endpoints\",\n        \"status\": \"in_progress\",\n        \"priority\": \"high\",\n        \"due_date\": \"2024-01-20T17:00:00Z\",\n        \"assignee\": {\n          \"id\": \"usr_abc123\",\n          \"name\": \"John Doe\",\n          \"email\": \"john@example.com\",\n          \"avatar_url\": \"https://cdn.taskmanager.com/avatars/usr_abc123.jpg\"\n        },\n        \"created_by\": {\n          \"id\": \"usr_xyz789\",\n          \"name\": \"Jane Smith\"\n        },\n        \"tags\": [\"documentation\", \"api\"],\n        \"comments_count\": 5,\n        \"attachments_count\": 2,\n        \"created_at\": \"2024-01-10T08:00:00Z\",\n        \"updated_at\": \"2024-01-15T14:30:00Z\"\n      }\n    ]\n  },\n  \"meta\": {\n    \"pagination\": {\n      \"current_page\": 1,\n      \"per_page\": 20,\n      \"total_pages\": 5,\n      \"total_count\": 98\n    },\n    \"filters_applied\": {\n      \"status\": \"in_progress\",\n      \"priority\": \"high\"\n    }\n  },\n  \"links\": {\n    \"self\": \"/v1/tasks?page=1&limit=20\",\n    \"first\": \"/v1/tasks?page=1&limit=20\",\n    \"prev\": null,\n    \"next\": \"/v1/tasks?page=2&limit=20\",\n    \"last\": \"/v1/tasks?page=5&limit=20\"\n  }\n}\n```\n\n### POST /tasks\nCreate a new task.\n\n**Request:**\n```http\nPOST /v1/tasks\nAuthorization: Bearer <access_token>\nContent-Type: application/json\n\n{\n  \"title\": \"Implement User Authentication\",\n  \"description\": \"Add JWT-based authentication with refresh tokens\",\n  \"status\": \"pending\",\n  \"priority\": \"high\",\n  \"due_date\": \"2024-01-25T17:00:00Z\",\n  \"assignee_id\": \"usr_abc123\",\n  \"tags\": [\"backend\", \"security\"],\n  \"parent_task_id\": null\n}\n```\n\n**Response (201 Created):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"task\": {\n      \"id\": \"tsk_ghi789\",\n      \"title\": \"Implement User Authentication\",\n      \"description\": \"Add JWT-based authentication with refresh tokens\",\n      \"status\": \"pending\",\n      \"priority\": \"high\",\n      \"due_date\": \"2024-01-25T17:00:00Z\",\n      \"assignee\": {\n        \"id\": \"usr_abc123\",\n        \"name\": \"John Doe\",\n        \"email\": \"john@example.com\"\n      },\n      \"created_by\": {\n        \"id\": \"usr_xyz789\",\n        \"name\": \"Jane Smith\"\n      },\n      \"tags\": [\"backend\", \"security\"],\n      \"parent_task_id\": null,\n      \"subtasks_count\": 0,\n      \"comments_count\": 0,\n      \"attachments_count\": 0,\n      \"created_at\": \"2024-01-15T10:30:00Z\",\n      \"updated_at\": \"2024-01-15T10:30:00Z\"\n    }\n  },\n  \"links\": {\n    \"self\": \"/v1/tasks/tsk_ghi789\",\n    \"comments\": \"/v1/tasks/tsk_ghi789/comments\",\n    \"attachments\": \"/v1/tasks/tsk_ghi789/attachments\"\n  }\n}\n```\n\n### GET /tasks/{task_id}\nRetrieve a specific task.\n\n**Request:**\n```http\nGET /v1/tasks/tsk_ghi789\nAuthorization: Bearer <access_token>\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"task\": {\n      \"id\": \"tsk_ghi789\",\n      \"title\": \"Implement User Authentication\",\n      \"description\": \"Add JWT-based authentication with refresh tokens\",\n      \"status\": \"in_progress\",\n      \"priority\": \"high\",\n      \"due_date\": \"2024-01-25T17:00:00Z\",\n      \"assignee\": {\n        \"id\": \"usr_abc123\",\n        \"name\": \"John Doe\",\n        \"email\": \"john@example.com\",\n        \"avatar_url\": \"https://cdn.taskmanager.com/avatars/usr_abc123.jpg\"\n      },\n      \"created_by\": {\n        \"id\": \"usr_xyz789\",\n        \"name\": \"Jane Smith\"\n      },\n      \"tags\": [\"backend\", \"security\"],\n      \"parent_task\": null,\n      \"subtasks\": [\n        {\n          \"id\": \"tsk_sub001\",\n          \"title\": \"Design token schema\",\n          \"status\": \"completed\"\n        },\n        {\n          \"id\": \"tsk_sub002\",\n          \"title\": \"Implement login endpoint\",\n          \"status\": \"in_progress\"\n        }\n      ],\n      \"recent_comments\": [\n        {\n          \"id\": \"cmt_abc123\",\n          \"content\": \"Started working on this\",\n          \"author\": {\n            \"id\": \"usr_abc123\",\n            \"name\": \"John Doe\"\n          },\n          \"created_at\": \"2024-01-16T09:00:00Z\"\n        }\n      ],\n      \"attachments\": [\n        {\n          \"id\": \"att_xyz789\",\n          \"filename\": \"auth_flow_diagram.png\",\n          \"content_type\": \"image/png\",\n          \"size_bytes\": 245678,\n          \"url\": \"https://cdn.taskmanager.com/attachments/att_xyz789\"\n        }\n      ],\n      \"activity_log\": [\n        {\n          \"action\": \"status_changed\",\n          \"from\": \"pending\",\n          \"to\": \"in_progress\",\n          \"actor\": {\n            \"id\": \"usr_abc123\",\n            \"name\": \"John Doe\"\n          },\n          \"timestamp\": \"2024-01-16T08:30:00Z\"\n        }\n      ],\n      \"created_at\": \"2024-01-15T10:30:00Z\",\n      \"updated_at\": \"2024-01-16T09:00:00Z\"\n    }\n  }\n}\n```\n\n### PUT /tasks/{task_id}\nUpdate a task (full replacement).\n\n**Request:**\n```http\nPUT /v1/tasks/tsk_ghi789\nAuthorization: Bearer <access_token>\nContent-Type: application/json\n\n{\n  \"title\": \"Implement User Authentication System\",\n  \"description\": \"Add JWT-based authentication with refresh tokens and OAuth2 support\",\n  \"status\": \"in_progress\",\n  \"priority\": \"urgent\",\n  \"due_date\": \"2024-01-23T17:00:00Z\",\n  \"assignee_id\": \"usr_abc123\",\n  \"tags\": [\"backend\", \"security\", \"oauth\"]\n}\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"task\": {\n      \"id\": \"tsk_ghi789\",\n      \"title\": \"Implement User Authentication System\",\n      \"description\": \"Add JWT-based authentication with refresh tokens and OAuth2 support\",\n      \"status\": \"in_progress\",\n      \"priority\": \"urgent\",\n      \"due_date\": \"2024-01-23T17:00:00Z\",\n      \"assignee\": {\n        \"id\": \"usr_abc123\",\n        \"name\": \"John Doe\"\n      },\n      \"tags\": [\"backend\", \"security\", \"oauth\"],\n      \"updated_at\": \"2024-01-16T11:00:00Z\"\n    }\n  }\n}\n```\n\n### PATCH /tasks/{task_id}\nPartially update a task.\n\n**Request:**\n```http\nPATCH /v1/tasks/tsk_ghi789\nAuthorization: Bearer <access_token>\nContent-Type: application/json\n\n{\n  \"status\": \"completed\",\n  \"priority\": \"medium\"\n}\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"task\": {\n      \"id\": \"tsk_ghi789\",\n      \"title\": \"Implement User Authentication System\",\n      \"status\": \"completed\",\n      \"priority\": \"medium\",\n      \"updated_at\": \"2024-01-20T15:00:00Z\"\n    }\n  }\n}\n```\n\n### DELETE /tasks/{task_id}\nDelete a task.\n\n**Request:**\n```http\nDELETE /v1/tasks/tsk_ghi789\nAuthorization: Bearer <access_token>\n```\n\n**Response (204 No Content)**\n\n---\n\n## 3. Comment Endpoints\n\n### GET /tasks/{task_id}/comments\nList comments for a task.\n\n**Request:**\n```http\nGET /v1/tasks/tsk_ghi789/comments?page=1&limit=20&sort=-created_at\nAuthorization: Bearer <access_token>\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"comments\": [\n      {\n        \"id\": \"cmt_abc123\",\n        \"content\": \"I've completed the initial implementation. Please review.\",\n        \"author\": {\n          \"id\": \"usr_abc123\",\n          \"name\": \"John Doe\",\n          \"avatar_url\": \"https://cdn.taskmanager.com/avatars/usr_abc123.jpg\"\n        },\n        \"mentions\": [\n          {\n            \"id\": \"usr_xyz789\",\n            \"name\": \"Jane Smith\"\n          }\n        ],\n        \"attachments\": [],\n        \"reactions\": {\n          \"thumbs_up\": 2,\n          \"heart\": 1\n        },\n        \"edited\": false,\n        \"created_at\": \"2024-01-18T14:30:00Z\",\n        \"updated_at\": \"2024-01-18T14:30:00Z\"\n      }\n    ]\n  },\n  \"meta\": {\n    \"pagination\": {\n      \"current_page\": 1,\n      \"per_page\": 20,\n      \"total_pages\": 2,\n      \"total_count\": 25\n    }\n  }\n}\n```\n\n### POST /tasks/{task_id}/comments\nAdd a comment to a task.\n\n**Request:**\n```http\nPOST /v1/tasks/tsk_ghi789/comments\nAuthorization: Bearer <access_token>\nContent-Type: application/json\n\n{\n  \"content\": \"Great progress! @usr_xyz789 can you review the security implementation?\",\n  \"mentions\": [\"usr_xyz789\"]\n}\n```\n\n**Response (201 Created):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"comment\": {\n      \"id\": \"cmt_def456\",\n      \"content\": \"Great progress! @usr_xyz789 can you review the security implementation?\",\n      \"author\": {\n        \"id\": \"usr_abc123\",\n        \"name\": \"John Doe\"\n      },\n      \"mentions\": [\n        {\n          \"id\": \"usr_xyz789\",\n          \"name\": \"Jane Smith\"\n        }\n      ],\n      \"created_at\": \"2024-01-19T10:00:00Z\"\n    }\n  }\n}\n```\n\n### PATCH /tasks/{task_id}/comments/{comment_id}\nUpdate a comment.\n\n**Request:**\n```http\nPATCH /v1/tasks/tsk_ghi789/comments/cmt_def456\nAuthorization: Bearer <access_token>\nContent-Type: application/json\n\n{\n  \"content\": \"Updated: Great progress! @usr_xyz789 please review when you have time.\"\n}\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"comment\": {\n      \"id\": \"cmt_def456\",\n      \"content\": \"Updated: Great progress! @usr_xyz789 please review when you have time.\",\n      \"edited\": true,\n      \"updated_at\": \"2024-01-19T10:30:00Z\"\n    }\n  }\n}\n```\n\n### DELETE /tasks/{task_id}/comments/{comment_id}\nDelete a comment.\n\n**Request:**\n```http\nDELETE /v1/tasks/tsk_ghi789/comments/cmt_def456\nAuthorization: Bearer <access_token>\n```\n\n**Response (204 No Content)**\n\n---\n\n## 4. Attachment Endpoints\n\n### GET /tasks/{task_id}/attachments\nList attachments for a task.\n\n**Request:**\n```http\nGET /v1/tasks/tsk_ghi789/attachments\nAuthorization: Bearer <access_token>\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"attachments\": [\n      {\n        \"id\": \"att_xyz789\",\n        \"filename\": \"auth_flow_diagram.png\",\n        \"original_filename\": \"auth_flow_diagram.png\",\n        \"content_type\": \"image/png\",\n        \"size_bytes\": 245678,\n        \"url\": \"https://cdn.taskmanager.com/attachments/att_xyz789\",\n        \"thumbnail_url\": \"https://cdn.taskmanager.com/attachments/att_xyz789/thumb\",\n        \"uploaded_by\": {\n          \"id\": \"usr_abc123\",\n          \"name\": \"John Doe\"\n        },\n        \"created_at\": \"2024-01-16T09:00:00Z\"\n      }\n    ]\n  },\n  \"meta\": {\n    \"total_count\": 3,\n    \"total_size_bytes\": 1245678\n  }\n}\n```\n\n### POST /tasks/{task_id}/attachments\nUpload an attachment.\n\n**Request:**\n```http\nPOST /v1/tasks/tsk_ghi789/attachments\nAuthorization: Bearer <access_token>\nContent-Type: multipart/form-data\n\n------WebKitFormBoundary\nContent-Disposition: form-data; name=\"file\"; filename=\"requirements.pdf\"\nContent-Type: application/pdf\n\n[binary data]\n------WebKitFormBoundary\nContent-Disposition: form-data; name=\"description\"\n\nProject requirements document\n------WebKitFormBoundary--\n```\n\n**Response (201 Created):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"attachment\": {\n      \"id\": \"att_new123\",\n      \"filename\": \"requirements.pdf\",\n      \"content_type\": \"application/pdf\",\n      \"size_bytes\": 1048576,\n      \"url\": \"https://cdn.taskmanager.com/attachments/att_new123\",\n      \"description\": \"Project requirements document\",\n      \"uploaded_by\": {\n        \"id\": \"usr_abc123\",\n        \"name\": \"John Doe\"\n      },\n      \"created_at\": \"2024-01-19T11:00:00Z\"\n    }\n  }\n}\n```\n\n### DELETE /tasks/{task_id}/attachments/{attachment_id}\nDelete an attachment.\n\n**Request:**\n```http\nDELETE /v1/tasks/tsk_ghi789/attachments/att_xyz789\nAuthorization: Bearer <access_token>\n```\n\n**Response (204 No Content)**\n\n---\n\n## 5. User Endpoints\n\n### GET /users\nList users (for assignee selection).\n\n**Request:**\n```http\nGET /v1/users?search=john&role=member&page=1&limit=20\nAuthorization: Bearer <access_token>\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"users\": [\n      {\n        \"id\": \"usr_abc123\",\n        \"name\": \"John Doe\",\n        \"email\": \"john@example.com\",\n        \"avatar_url\": \"https://cdn.taskmanager.com/avatars/usr_abc123.jpg\",\n        \"role\": \"member\",\n        \"department\": \"Engineering\",\n        \"active\": true\n      }\n    ]\n  },\n  \"meta\": {\n    \"pagination\": {\n      \"current_page\": 1,\n      \"per_page\": 20,\n      \"total_count\": 1\n    }\n  }\n}\n```\n\n### GET /users/me\nGet current user profile.\n\n**Request:**\n```http\nGET /v1/users/me\nAuthorization: Bearer <access_token>\n```\n\n**Response (200 OK):**\n```json\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"user\": {\n      \"id\": \"usr_abc123\",\n      \"email\": \"john@example.com\",\n      \"name\": \"John Doe\",\n      \"avatar_url\": \"https://cdn.taskmanager.com/avatars/usr_abc123.jpg\",\n      \"role\": \"admin\",\n      \"permissions\": [\"task:read\", \"task:write\", \"task:delete\", \"user:manage\"],\n      \"department\": \"Engineering\",\n      \"timezone\": \"America/New_York\",\n      \"notification_preferences\": {\n        \"email\": true,\n        \"push\": true,\n        \"task_assigned\": true,\n        \"task_updated\": true,\n        \"comment_mention\": true\n      },\n      \"created_at\": \"2024-01-01T00:00:00Z\"\n    }\n  }\n}\n```\n\n---\n\n## Error Handling Strategy\n\n### Standard Error Response Format\n\n```json\n{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"The request contains invalid parameters\",\n    \"details\": [\n      {\n        \"field\": \"due_date\",\n        \"message\": \"Due date must be in the future\",\n        \"code\": \"INVALID_DATE\"\n      },\n      {\n        \"field\": \"priority\",\n        \"message\": \"Priority must be one of: low, medium, high, urgent\",\n        \"code\": \"INVALID_ENUM\"\n      }\n    ],\n    \"request_id\": \"req_abc123xyz\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"documentation_url\": \"https://docs.taskmanager.com/errors/VALIDATION_ERROR\"\n  }\n}\n```\n\n### HTTP Status Codes and Error Codes\n\n| HTTP Status | Error Code | Description |\n|-------------|------------|-------------|\n| 400 | VALIDATION_ERROR | Invalid request parameters |\n| 400 | MALFORMED_JSON | Request body is not valid JSON |\n| 401 | AUTHENTICATION_REQUIRED | No authentication token provided |\n| 401 | TOKEN_EXPIRED | Access token has expired |\n| 401 | TOKEN_INVALID | Token is malformed or invalid |\n| 403 | PERMISSION_DENIED | User lacks required permissions |\n| 403 | RESOURCE_FORBIDDEN | Access to resource is forbidden |\n| 404 | RESOURCE_NOT_FOUND | Requested resource does not exist |\n| 405 | METHOD_NOT_ALLOWED | HTTP method not supported |\n| 409 | CONFLICT | Resource conflict (e.g., duplicate) |\n| 413 | PAYLOAD_TOO_LARGE | Request body exceeds size limit |\n| 415 | UNSUPPORTED_MEDIA_TYPE | Content-Type not supported |\n| 422 | UNPROCESSABLE_ENTITY | Request understood but cannot process |\n| 429 | RATE_LIMIT_EXCEEDED | Too many requests |\n| 500 | INTERNAL_ERROR | Unexpected server error |\n| 502 | BAD_GATEWAY | Upstream service error |\n| 503 | SERVICE_UNAVAILABLE | Service temporarily unavailable |\n\n### Error Response Examples\n\n**401 Unauthorized - Token Expired:**\n```json\n{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"TOKEN_EXPIRED\",\n    \"message\": \"Your access token has expired. Please refresh your token.\",\n    \"request_id\": \"req_abc123xyz\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n  }\n}\n```\n\n**403 Forbidden - Permission Denied:**\n```json\n{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"PERMISSION_DENIED\",\n    \"message\": \"You do not have permission to delete this task\",\n    \"details\": {\n      \"required_permission\": \"task:delete\",\n      \"user_permissions\": [\"task:read\", \"task:write\"],\n      \"resource_id\": \"tsk_ghi789\"\n    },\n    \"request_id\": \"req_def456uvw\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n  }\n}\n```\n\n**404 Not Found:**\n```json\n{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"The requested task does not exist\",\n    \"details\": {\n      \"resource_type\": \"task\",\n      \"resource_id\": \"tsk_invalid123\"\n    },\n    \"request_id\": \"req_ghi789rst\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n  }\n}\n```\n\n**429 Rate Limited:**\n```json\n{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"RATE_LIMIT_EXCEEDED\",\n    \"message\": \"Rate limit exceeded. Please retry after 60 seconds.\",\n    \"details\": {\n      \"limit\": 100,\n      \"window\": \"60s\",\n      \"retry_after\": 45\n    },\n    \"request_id\": \"req_jkl012mno\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n  }\n}\n```\n\n---\n\n## Rate Limiting Recommendations\n\n### Rate Limit Tiers\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Rate Limiting Strategy                    │\n├─────────────────────────────────────────────────────────────┤\n│                                                              │\n│  Tier 1: Anonymous/Public                                    │\n│  ├── 20 requests/minute                                      │\n│  └── Endpoints: /auth/login, /auth/register                  │\n│                                                              │\n│  Tier 2: Authenticated (Free)                                │\n│  ├── 100 requests/minute                                     │\n│  ├── 1,000 requests/hour                                     │\n│  └── All authenticated endpoints                             │\n│                                                              │\n│  Tier 3: Authenticated (Pro)                                 │\n│  ├── 500 requests/minute                                     │\n│  ├── 10,000 requests/hour                                    │\n│  └── All authenticated endpoints                             │\n│                                                              │\n│  Tier 4: Authenticated (Enterprise)                          │\n│  ├── 2,000 requests/minute                                   │\n│  ├── 100,000 requests/hour                                   │\n│  └── Custom limits available                                 │\n│                                                              │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Rate Limit Headers\n\nEvery response includes rate limit information:\n\n```http\nHTTP/1.1 200 OK\nX-RateLimit-Limit: 100\nX-RateLimit-Remaining: 95\nX-RateLimit-Reset: 1705320000\nX-RateLimit-Window: 60\nRetry-After: 45  (only when rate limited)\n```\n\n### Endpoint-Specific Limits\n\n| Endpoint Category | Limit | Window | Reason |\n|-------------------|-------|--------|--------|\n| Authentication | 10 | 1 min | Prevent brute force |\n| File Upload | 20 | 1 min | Resource intensive |\n| Search | 30 | 1 min | Database intensive |\n| Read Operations | 200 | 1 min | Standard operations |\n| Write Operations | 50 | 1 min | Prevent spam |\n| Bulk Operations | 10 | 1 min | Resource intensive |\n\n### Implementation: Token Bucket Algorithm\n\n```python\n# Pseudocode for rate limiting implementation\nclass RateLimiter:\n    def __init__(self, capacity, refill_rate):\n        self.capacity = capacity      # Max tokens\n        self.refill_rate = refill_rate  # Tokens per second\n        \n    def allow_request(self, user_id):\n        bucket = self.get_bucket(user_id)\n        current_time = time.now()\n        \n        # Refill tokens based on elapsed time\n        elapsed = current_time - bucket.last_refill\n        bucket.tokens = min(\n            self.capacity,\n            bucket.tokens + (elapsed * self.refill_rate)\n        )\n        bucket.last_refill = current_time\n        \n        if bucket.tokens >= 1:\n            bucket.tokens -= 1\n            return True, bucket.tokens\n        \n        return False, 0\n```\n\n---\n\n## Authorisation Model\n\n### Role-Based Access Control (RBAC)\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Permission Matrix                         │\n├──────────────┬──────────┬──────────┬──────────┬────────────┤\n│ Permission   │  Viewer  │  Member  │  Admin   │   Owner    │\n├──────────────┼──────────┼──────────┼──────────┼────────────┤\n│ task:read    │    ✓     │    ✓     │    ✓     │     ✓      │\n│ task:create  │    ✗     │    ✓     │    ✓     │     ✓      │\n│ task:update  │    ✗     │    Own   │    ✓     │     ✓      │\n│ task:delete  │    ✗     │    Own   │    ✓     │     ✓      │\n│ task:assign  │    ✗     │    ✗     │    ✓     │     ✓      │\n│ comment:*    │    ✗     │    ✓     │    ✓     │     ✓      │\n│ user:read    │    ✓     │    ✓     │    ✓     │     ✓      │\n│ user:manage  │    ✗     │    ✗     │    ✓     │     ✓      │\n│ settings:*   │    ✗     │    ✗     │    ✗     │     ✓      │\n└──────────────┴──────────┴──────────┴──────────┴────────────┘\n```\n\n### Resource-Level Permissions\n\n```json\n// Task with resource-level permissions\n{\n  \"id\": \"tsk_ghi789\",\n  \"title\": \"Confidential Task\",\n  \"visibility\": \"restricted\",\n  \"permissions\": {\n    \"viewers\": [\"usr_abc123\", \"usr_def456\"],\n    \"editors\": [\"usr_ghi789\"],\n    \"admins\": [\"usr_owner01\"]\n  }\n}\n```\n\n---\n\n## API Versioning Strategy\n\n### URL Path Versioning (Recommended)\n```\nhttps://api.taskmanager.com/v1/tasks\nhttps://api.taskmanager.com/v2/tasks\n```\n\n### Deprecation Headers\n```http\nHTTP/1.1 200 OK\nDeprecation: Sun, 01 Jun 2025 00:00:00 GMT\nSunset: Sun, 01 Dec 2025 00:00:00 GMT\nLink: <https://api.taskmanager.com/v2/tasks>; rel=\"successor-version\"\n```\n\n---\n\n## Complete OpenAPI Specification Summary\n\n```yaml\nopenapi: 3.0.3\ninfo:\n  title: Task Management API\n  version: 1.0.0\n  description: RESTful API for task management system\n\nservers:\n  - url: https://api.taskmanager.com/v1\n    description: Production server\n  - url: https://staging-api.taskmanager.com/v1\n    description: Staging server\n\nsecurity:\n  - bearerAuth: []\n\ntags:\n  - name: Authentication\n  - name: Tasks\n  - name: Comments\n  - name: Attachments\n  - name: Users\n\npaths:\n  /auth/login:\n    post:\n      tags: [Authentication]\n      summary: Authenticate user\n      security: []\n      \n  /tasks:\n    get:\n      tags: [Tasks]\n      summary: List tasks\n      parameters:\n        - $ref: '#/components/parameters/PageParam'\n        - $ref: '#/components/parameters/LimitParam'\n        - $ref: '#/components/parameters/StatusFilter'\n        \n    post:\n      tags: [Tasks]\n      summary: Create task\n      \n  /tasks/{taskId}:\n    get:\n      tags: [Tasks]\n      summary: Get task\n    put:\n      tags: [Tasks]\n      summary: Update task\n    patch:\n      tags: [Tasks]\n      summary: Partial update task\n    delete:\n      tags: [Tasks]\n      summary: Delete task\n\ncomponents:\n  securitySchemes:\n    bearerAuth:\n      type: http\n      scheme: bearer\n      bearerFormat: JWT\n      \n  schemas:\n    Task:\n      type: object\n      properties:\n        id:\n          type: string\n        title:\n          type: string\n        status:\n          type: string\n          enum: [pending, in_progress, completed, cancelled]\n        priority:\n          type: string\n          enum: [low, medium, high, urgent]\n```\n\n---\n\n## Security Best Practices Implemented\n\n1. **JWT with RS256** - Asymmetric signing for better security\n2. **Short-lived access tokens** - 15-minute expiry\n3. **Refresh token rotation** - New refresh token on each use\n4. **Rate limiting** - Prevent abuse and DDoS\n5. **Input validation** - Strict schema validation\n6. **HTTPS only** - All traffic encrypted\n7. **CORS configuration** - Restrict allowed origins\n8. **Request ID tracking** - Full audit trail\n9. **Principle of least privilege** - Granular permissions\n10. **Secure headers** - CSP, HSTS, X-Content-Type-Options",
    "tokensIn": 128,
    "tokensOut": 9318,
    "cost": 0.23359000000000002,
    "durationMs": 82376,
    "success": true
  },
  {
    "testName": "Security Audit",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "Perform a security audit on this Node.js/Express code. Identify all security vulnerabilities, rate their severity (Critical/High/Medium/Low), and provide fixes:\n\n```javascript\n\nconst express = require('express');\nconst mysql = require('mysql');\nconst app = express();\n\nconst db = mysql.createConnection({\n  host: 'localhost',\n  user: 'root',\n  password: 'admin123',\n  database: 'users'\n});\n\napp.get('/user', (req, res) => {\n  const userId = req.query.id;\n  db.query(`SELECT * FROM users WHERE id = ${userId}`, (err, results) => {\n    res.json(results);\n  });\n});\n\napp.post('/login', (req, res) => {\n  const { username, password } = req.body;\n  db.query(`SELECT * FROM users WHERE username = '${username}' AND password = '${password}'`, (err, results) => {\n    if (results.length > 0) {\n      res.cookie('user', username);\n      res.json({ success: true, user: results[0] });\n    } else {\n      res.json({ success: false });\n    }\n  });\n});\n\napp.get('/file', (req, res) => {\n  const filename = req.query.name;\n  res.sendFile('/uploads/' + filename);\n});\n\napp.listen(3000);\n\n```",
    "response": "# Security Audit Report\n\n## Summary\nThis code contains **8 critical/high vulnerabilities** that could lead to complete system compromise.\n\n---\n\n## Vulnerability Analysis\n\n### 1. SQL Injection (Critical) ⚠️\n**Location:** `/user` and `/login` endpoints\n\n**Issue:** User input is directly concatenated into SQL queries.\n\n**Exploit Example:**\n```\nGET /user?id=1 OR 1=1; DROP TABLE users;--\nPOST /login with username: admin'--\n```\n\n**Fix:**\n```javascript\n// Use parameterized queries\napp.get('/user', (req, res) => {\n  const userId = req.query.id;\n  \n  // Validate input type\n  if (!userId || isNaN(parseInt(userId))) {\n    return res.status(400).json({ error: 'Invalid user ID' });\n  }\n  \n  db.query('SELECT id, username, email FROM users WHERE id = ?', [userId], (err, results) => {\n    if (err) {\n      return res.status(500).json({ error: 'Database error' });\n    }\n    res.json(results);\n  });\n});\n\napp.post('/login', (req, res) => {\n  const { username, password } = req.body;\n  db.query('SELECT * FROM users WHERE username = ?', [username], async (err, results) => {\n    if (results.length > 0) {\n      const valid = await bcrypt.compare(password, results[0].password_hash);\n      // ... rest of login logic\n    }\n  });\n});\n```\n\n---\n\n### 2. Hardcoded Credentials (Critical) ⚠️\n**Location:** Database connection configuration\n\n**Issue:** Credentials exposed in source code.\n\n**Fix:**\n```javascript\nrequire('dotenv').config();\n\nconst db = mysql.createConnection({\n  host: process.env.DB_HOST,\n  user: process.env.DB_USER,\n  password: process.env.DB_PASSWORD,\n  database: process.env.DB_NAME\n});\n```\n\n**.env file (never commit):**\n```\nDB_HOST=localhost\nDB_USER=app_user\nDB_PASSWORD=<strong-random-password>\nDB_NAME=users\n```\n\n---\n\n### 3. Plaintext Password Storage (Critical) ⚠️\n**Location:** `/login` endpoint\n\n**Issue:** Passwords compared as plaintext, implying insecure storage.\n\n**Fix:**\n```javascript\nconst bcrypt = require('bcrypt');\nconst SALT_ROUNDS = 12;\n\n// Registration\napp.post('/register', async (req, res) => {\n  const { username, password } = req.body;\n  const passwordHash = await bcrypt.hash(password, SALT_ROUNDS);\n  db.query('INSERT INTO users (username, password_hash) VALUES (?, ?)', \n    [username, passwordHash]);\n});\n\n// Login\nconst valid = await bcrypt.compare(password, results[0].password_hash);\n```\n\n---\n\n### 4. Path Traversal (High) ⚠️\n**Location:** `/file` endpoint\n\n**Issue:** Attacker can access arbitrary files: `?name=../../../etc/passwd`\n\n**Fix:**\n```javascript\nconst path = require('path');\n\napp.get('/file', (req, res) => {\n  const filename = req.query.name;\n  \n  if (!filename) {\n    return res.status(400).json({ error: 'Filename required' });\n  }\n  \n  // Sanitize and validate path\n  const safeName = path.basename(filename); // Strips directory traversal\n  const uploadsDir = path.resolve(__dirname, 'uploads');\n  const filePath = path.join(uploadsDir, safeName);\n  \n  // Verify file is within uploads directory\n  if (!filePath.startsWith(uploadsDir)) {\n    return res.status(403).json({ error: 'Access denied' });\n  }\n  \n  res.sendFile(filePath);\n});\n```\n\n---\n\n### 5. Insecure Cookie Configuration (High)\n**Location:** `/login` response\n\n**Issue:** Cookie lacks security flags.\n\n**Fix:**\n```javascript\n// Use secure session management instead\nconst session = require('express-session');\n\napp.use(session({\n  secret: process.env.SESSION_SECRET,\n  resave: false,\n  saveUninitialized: false,\n  cookie: {\n    httpOnly: true,      // Prevents XSS access\n    secure: true,        // HTTPS only\n    sameSite: 'strict',  // CSRF protection\n    maxAge: 3600000      // 1 hour expiry\n  }\n}));\n```\n\n---\n\n### 6. Missing Input Validation & Body Parser (Medium)\n**Location:** All endpoints\n\n**Fix:**\n```javascript\nconst helmet = require('helmet');\nconst rateLimit = require('express-rate-limit');\nconst { body, query, validationResult } = require('express-validator');\n\napp.use(helmet());\napp.use(express.json({ limit: '10kb' }));\n\nconst limiter = rateLimit({\n  windowMs: 15 * 60 * 1000,\n  max: 100\n});\napp.use(limiter);\n\napp.post('/login', [\n  body('username').isAlphanumeric().isLength({ min: 3, max: 30 }),\n  body('password').isLength({ min: 8, max: 128 })\n], (req, res) => {\n  const errors = validationResult(req);\n  if (!errors.isEmpty()) {\n    return res.status(400).json({ errors: errors.array() });\n  }\n  // ... rest of handler\n});\n```\n\n---\n\n### 7. No Error Handling (Medium)\n**Location:** All database queries\n\n**Fix:**\n```javascript\napp.get('/user', async (req, res) => {\n  try {\n    // ... query logic\n  } catch (error) {\n    console.error('Database error:', error.message); // Log safely\n    res.status(500).json({ error: 'Internal server error' }); // Generic response\n  }\n});\n\n// Global error handler\napp.use((err, req, res, next) => {\n  console.error(err.stack);\n  res.status(500).json({ error: 'Something went wrong' });\n});\n```\n\n---\n\n### 8. Information Disclosure (Medium)\n**Location:** `/user` returns `SELECT *`\n\n**Fix:**\n```javascript\n// Only return necessary fields\ndb.query('SELECT id, username, email, created_at FROM users WHERE id = ?', [userId]);\n```\n\n---\n\n## Secure Refactored Code\n\n```javascript\nrequire('dotenv').config();\nconst express = require('express');\nconst mysql = require('mysql2/promise');\nconst bcrypt = require('bcrypt');\nconst helmet = require('helmet');\nconst session = require('express-session');\nconst rateLimit = require('express-rate-limit');\nconst { body, query, validationResult } = require('express-validator');\nconst path = require('path');\n\nconst app = express();\n\n// Security middleware\napp.use(helmet());\napp.use(express.json({ limit: '10kb' }));\napp.use(rateLimit({ windowMs: 15 * 60 * 1000, max: 100 }));\napp.use(session({\n  secret: process.env.SESSION_SECRET,\n  resave: false,\n  saveUninitialized: false,\n  cookie: { httpOnly: true, secure: true, sameSite: 'strict' }\n}));\n\n// Database pool\nconst pool = mysql.createPool({\n  host: process.env.DB_HOST,\n  user: process.env.DB_USER,\n  password: process.env.DB_PASSWORD,\n  database: process.env.DB_NAME,\n  waitForConnections: true,\n  connectionLimit: 10\n});\n\n// Routes with validation\napp.get('/user', [\n  query('id').isInt({ min: 1 })\n], async (req, res) => {\n  if (!validationResult(req).isEmpty()) {\n    return res.status(400).json({ error: 'Invalid ID' });\n  }\n  try {\n    const [rows] = await pool.execute(\n      'SELECT id, username, email FROM users WHERE id = ?',\n      [req.query.id]\n    );\n    res.json(rows[0] || null);\n  } catch (err) {\n    res.status(500).json({ error: 'Server error' });\n  }\n});\n\napp.listen(3000, '127.0.0.1');\n```\n\n---\n\n## Severity Summary\n\n| Vulnerability | Severity | CVSS Est. |\n|--------------|----------|-----------|\n| SQL Injection | Critical | 9.8 |\n| Hardcoded Credentials | Critical | 9.1 |\n| Plaintext Passwords | Critical | 9.1 |\n| Path Traversal | High | 7.5 |\n| Insecure Cookies | High | 7.1 |\n| Missing Validation | Medium | 5.3 |\n| No Error Handling | Medium | 5.0 |\n| Info Disclosure | Medium | 4.3 |",
    "tokensIn": 359,
    "tokensOut": 2259,
    "cost": 0.05827,
    "durationMs": 25043,
    "success": true
  },
  {
    "testName": "Architecture Decision",
    "framework": "pi-agent-sdk",
    "model": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "prompt": "A startup is building a real-time collaboration platform (like Google Docs) with these requirements:\n- Support 10,000 concurrent users per document\n- Sub-100ms latency for edits\n- Offline support with sync\n- Version history and conflict resolution\n- Multi-region deployment\n\nCompare and recommend architectures:\n1. WebSocket vs Server-Sent Events vs WebRTC\n2. CRDT vs Operational Transformation\n3. Database choice (PostgreSQL vs MongoDB vs custom)\n4. Message queue selection\n\nProvide a detailed recommendation with trade-offs.",
    "response": "# Real-Time Collaboration Platform Architecture Recommendation\n\n## Executive Summary\n\nFor a Google Docs-like platform supporting 10,000 concurrent users per document with sub-100ms latency, I recommend:\n\n- **Transport**: WebSocket with WebRTC for P2P optimization\n- **Conflict Resolution**: CRDT (specifically Yjs)\n- **Database**: PostgreSQL + Redis + S3\n- **Message Queue**: Apache Kafka\n\n---\n\n## 1. Transport Layer Comparison\n\n### WebSocket vs SSE vs WebRTC\n\n```\n┌─────────────────┬────────────┬─────────────┬─────────────┐\n│ Feature         │ WebSocket  │ SSE         │ WebRTC      │\n├─────────────────┼────────────┼─────────────┼─────────────┤\n│ Direction       │ Bi-direct  │ Server→Only │ Bi-direct   │\n│ Latency         │ ~50ms      │ ~100ms      │ ~10ms (P2P) │\n│ Connection Limit│ ~65k/server│ 6/browser   │ Mesh limited│\n│ Offline Support │ Manual     │ Manual      │ Manual      │\n│ Firewall Issues │ Low        │ Very Low    │ High        │\n│ Server Load     │ Medium     │ Low         │ Very Low    │\n│ Complexity      │ Low        │ Very Low    │ High        │\n└─────────────────┴────────────┴─────────────┴─────────────┘\n```\n\n### Recommendation: Hybrid WebSocket + WebRTC\n\n```typescript\n// Connection Strategy Implementation\nclass ConnectionManager {\n  private wsConnection: WebSocket | null = null;\n  private rtcConnections: Map<string, RTCPeerConnection> = new Map();\n  private localPeers: Set<string> = new Set();\n  \n  async initialize(documentId: string, userId: string): Promise<void> {\n    // Primary: WebSocket for reliability and signaling\n    this.wsConnection = await this.establishWebSocket(documentId, userId);\n    \n    // Secondary: WebRTC for nearby peers (same region)\n    await this.discoverAndConnectPeers(documentId);\n  }\n  \n  private async establishWebSocket(docId: string, userId: string): Promise<WebSocket> {\n    const ws = new WebSocket(`wss://collab.example.com/docs/${docId}`);\n    \n    ws.onmessage = (event) => {\n      const message = JSON.parse(event.data);\n      \n      switch (message.type) {\n        case 'peer-discovery':\n          // Connect to nearby peers via WebRTC\n          this.handlePeerDiscovery(message.peers);\n          break;\n        case 'operation':\n          // Apply remote operation\n          this.handleRemoteOperation(message.operation);\n          break;\n        case 'webrtc-signal':\n          // Handle WebRTC signaling\n          this.handleSignaling(message);\n          break;\n      }\n    };\n    \n    return ws;\n  }\n  \n  // Send operation with automatic routing\n  sendOperation(operation: Operation): void {\n    const encoded = this.encodeOperation(operation);\n    \n    // Send via WebRTC to local peers (faster)\n    for (const [peerId, connection] of this.rtcConnections) {\n      if (connection.connectionState === 'connected') {\n        connection.dataChannel?.send(encoded);\n      }\n    }\n    \n    // Always send via WebSocket for persistence and remote peers\n    this.wsConnection?.send(JSON.stringify({\n      type: 'operation',\n      operation: operation,\n      timestamp: Date.now()\n    }));\n  }\n}\n```\n\n### Server-Side WebSocket Handler\n\n```typescript\n// High-performance WebSocket server using uWebSockets.js\nimport { App, WebSocket } from 'uWebSockets.js';\n\ninterface DocumentSession {\n  documentId: string;\n  userId: string;\n  region: string;\n}\n\nconst documentRooms = new Map<string, Set<WebSocket<DocumentSession>>>();\n\nconst app = App()\n  .ws<DocumentSession>('/docs/:documentId', {\n    /* Options */\n    maxPayloadLength: 16 * 1024 * 1024, // 16MB max\n    idleTimeout: 120,\n    compression: 1, // SHARED_COMPRESSOR\n    \n    upgrade: (res, req, context) => {\n      const documentId = req.getParameter(0);\n      const userId = req.getHeader('x-user-id');\n      const region = req.getHeader('x-region') || 'us-east-1';\n      \n      res.upgrade(\n        { documentId, userId, region },\n        req.getHeader('sec-websocket-key'),\n        req.getHeader('sec-websocket-protocol'),\n        req.getHeader('sec-websocket-extensions'),\n        context\n      );\n    },\n    \n    open: (ws) => {\n      const { documentId, userId, region } = ws.getUserData();\n      \n      // Join document room\n      ws.subscribe(`doc:${documentId}`);\n      ws.subscribe(`doc:${documentId}:region:${region}`);\n      \n      // Track connection\n      if (!documentRooms.has(documentId)) {\n        documentRooms.set(documentId, new Set());\n      }\n      documentRooms.get(documentId)!.add(ws);\n      \n      // Send current document state\n      sendDocumentState(ws, documentId);\n      \n      // Notify peers for WebRTC discovery\n      broadcastPeerDiscovery(documentId, region);\n    },\n    \n    message: async (ws, message, isBinary) => {\n      const { documentId } = ws.getUserData();\n      const data = JSON.parse(Buffer.from(message).toString());\n      \n      switch (data.type) {\n        case 'operation':\n          await handleOperation(ws, documentId, data.operation);\n          break;\n        case 'cursor':\n          broadcastCursor(ws, documentId, data);\n          break;\n        case 'webrtc-signal':\n          forwardSignaling(ws, data);\n          break;\n      }\n    },\n    \n    close: (ws, code, message) => {\n      const { documentId, userId } = ws.getUserData();\n      documentRooms.get(documentId)?.delete(ws);\n      broadcastUserLeft(documentId, userId);\n    }\n  });\n\nasync function handleOperation(\n  ws: WebSocket<DocumentSession>,\n  documentId: string,\n  operation: any\n): Promise<void> {\n  const startTime = process.hrtime.bigint();\n  \n  // 1. Validate operation\n  if (!validateOperation(operation)) {\n    ws.send(JSON.stringify({ type: 'error', message: 'Invalid operation' }));\n    return;\n  }\n  \n  // 2. Apply to CRDT state\n  await applyOperation(documentId, operation);\n  \n  // 3. Broadcast to all subscribers\n  app.publish(`doc:${documentId}`, JSON.stringify({\n    type: 'operation',\n    operation,\n    origin: ws.getUserData().userId\n  }));\n  \n  // 4. Queue for persistence\n  await persistenceQueue.add({ documentId, operation });\n  \n  const latency = Number(process.hrtime.bigint() - startTime) / 1_000_000;\n  metrics.recordLatency('operation_broadcast', latency);\n}\n```\n\n---\n\n## 2. Conflict Resolution: CRDT vs Operational Transformation\n\n### Detailed Comparison\n\n```\n┌──────────────────────┬─────────────────────┬─────────────────────┐\n│ Aspect               │ CRDT                │ OT                  │\n├──────────────────────┼─────────────────────┼─────────────────────┤\n│ Complexity           │ Medium              │ Very High           │\n│ Server Required      │ No (P2P capable)    │ Yes (central)       │\n│ Offline Support      │ Excellent           │ Complex             │\n│ Merge Correctness    │ Mathematically      │ Requires careful    │\n│                      │ guaranteed          │ implementation      │\n│ Memory Usage         │ Higher (tombstones) │ Lower               │\n│ Intent Preservation  │ Good with RGA       │ Excellent           │\n│ Implementation       │ Yjs, Automerge      │ Google Docs, OT.js  │\n│ Latency              │ Lower (no transform)│ Higher (transform)  │\n└──────────────────────┴─────────────────────┴─────────────────────┘\n```\n\n### Recommendation: CRDT with Yjs\n\n```typescript\n// CRDT Implementation using Yjs\nimport * as Y from 'yjs';\nimport { IndexeddbPersistence } from 'y-indexeddb';\nimport { WebsocketProvider } from 'y-websocket';\n\nclass CollaborativeDocument {\n  private doc: Y.Doc;\n  private text: Y.Text;\n  private awareness: awarenessProtocol.Awareness;\n  private wsProvider: WebsocketProvider;\n  private indexeddbProvider: IndexeddbPersistence;\n  private undoManager: Y.UndoManager;\n  \n  constructor(documentId: string, userId: string) {\n    // Initialize Yjs document\n    this.doc = new Y.Doc();\n    this.text = this.doc.getText('content');\n    \n    // Setup awareness for cursors and presence\n    this.awareness = new awarenessProtocol.Awareness(this.doc);\n    this.awareness.setLocalState({\n      user: { id: userId, name: '', color: this.generateColor(userId) },\n      cursor: null\n    });\n    \n    // Offline persistence with IndexedDB\n    this.indexeddbProvider = new IndexeddbPersistence(documentId, this.doc);\n    this.indexeddbProvider.on('synced', () => {\n      console.log('Loaded from IndexedDB');\n    });\n    \n    // WebSocket sync\n    this.wsProvider = new WebsocketProvider(\n      'wss://collab.example.com',\n      documentId,\n      this.doc,\n      { awareness: this.awareness }\n    );\n    \n    // Undo/Redo support\n    this.undoManager = new Y.UndoManager(this.text, {\n      trackedOrigins: new Set([this.doc.clientID])\n    });\n    \n    // Setup observers\n    this.setupObservers();\n  }\n  \n  private setupObservers(): void {\n    // Text changes\n    this.text.observe((event, transaction) => {\n      if (transaction.local) return;\n      \n      // Apply remote changes to editor\n      this.applyDeltaToEditor(event.delta);\n    });\n    \n    // Awareness changes (cursors, selections)\n    this.awareness.on('change', ({ added, updated, removed }) => {\n      this.updateRemoteCursors();\n    });\n    \n    // Connection status\n    this.wsProvider.on('status', ({ status }) => {\n      this.updateConnectionStatus(status);\n    });\n  }\n  \n  // Insert text at position\n  insert(index: number, text: string): void {\n    this.doc.transact(() => {\n      this.text.insert(index, text);\n    }, this.doc.clientID);\n  }\n  \n  // Delete text range\n  delete(index: number, length: number): void {\n    this.doc.transact(() => {\n      this.text.delete(index, length);\n    }, this.doc.clientID);\n  }\n  \n  // Get version vector for sync\n  getStateVector(): Uint8Array {\n    return Y.encodeStateVector(this.doc);\n  }\n  \n  // Apply remote state update\n  applyUpdate(update: Uint8Array): void {\n    Y.applyUpdate(this.doc, update);\n  }\n  \n  // Generate diff for sync\n  getStateDiff(remoteVector: Uint8Array): Uint8Array {\n    return Y.encodeStateAsUpdate(this.doc, remoteVector);\n  }\n  \n  // Snapshot for version history\n  createSnapshot(): Uint8Array {\n    return Y.encodeStateAsUpdate(this.doc);\n  }\n  \n  // Restore from snapshot\n  restoreSnapshot(snapshot: Uint8Array): void {\n    const tempDoc = new Y.Doc();\n    Y.applyUpdate(tempDoc, snapshot);\n    \n    // Merge snapshot into current doc\n    const diff = Y.encodeStateAsUpdate(tempDoc, Y.encodeStateVector(this.doc));\n    Y.applyUpdate(this.doc, diff);\n  }\n}\n```\n\n### Advanced CRDT Operations for Rich Text\n\n```typescript\n// Rich text CRDT with formatting\nclass RichTextCRDT {\n  private doc: Y.Doc;\n  private xmlFragment: Y.XmlFragment;\n  \n  constructor(documentId: string) {\n    this.doc = new Y.Doc();\n    this.xmlFragment = this.doc.getXmlFragment('content');\n  }\n  \n  // Apply formatting to range\n  formatRange(\n    start: number,\n    end: number,\n    format: { bold?: boolean; italic?: boolean; link?: string }\n  ): void {\n    this.doc.transact(() => {\n      const elements = this.getElementsInRange(start, end);\n      \n      for (const element of elements) {\n        if (format.bold !== undefined) {\n          element.setAttribute('bold', format.bold.toString());\n        }\n        if (format.italic !== undefined) {\n          element.setAttribute('italic', format.italic.toString());\n        }\n        if (format.link !== undefined) {\n          element.setAttribute('href', format.link);\n        }\n      }\n    });\n  }\n  \n  // Insert embedded content (images, tables)\n  insertEmbed(index: number, type: string, data: any): void {\n    this.doc.transact(() => {\n      const embed = new Y.XmlElement(type);\n      \n      for (const [key, value] of Object.entries(data)) {\n        embed.setAttribute(key, JSON.stringify(value));\n      }\n      \n      this.xmlFragment.insert(index, [embed]);\n    });\n  }\n  \n  // Handle comments as separate CRDT\n  private comments: Y.Map<any>;\n  \n  addComment(\n    rangeStart: number,\n    rangeEnd: number,\n    userId: string,\n    text: string\n  ): string {\n    const commentId = generateId();\n    \n    this.doc.transact(() => {\n      this.comments.set(commentId, {\n        id: commentId,\n        rangeStart,\n        rangeEnd,\n        userId,\n        text,\n        timestamp: Date.now(),\n        resolved: false,\n        replies: []\n      });\n    });\n    \n    return commentId;\n  }\n}\n```\n\n---\n\n## 3. Database Architecture\n\n### Recommendation: PostgreSQL + Redis + S3 (Polyglot Persistence)\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                     Database Architecture                        │\n├─────────────────────────────────────────────────────────────────┤\n│                                                                  │\n│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐         │\n│  │   Redis     │    │ PostgreSQL  │    │     S3      │         │\n│  │  Cluster    │    │   (Citus)   │    │  (Snapshots)│         │\n│  ├─────────────┤    ├─────────────┤    ├─────────────┤         │\n│  │ • Live CRDT │    │ • Users     │    │ • Doc       │         │\n│  │   state     │    │ • Documents │    │   snapshots │         │\n│  │ • Presence  │    │   metadata  │    │ • Version   │         │\n│  │ • Cursors   │    │ • Versions  │    │   history   │         │\n│  │ • Pub/Sub   │    │ • Sharing   │    │ • Exports   │         │\n│  │ • Rate      │    │ • Analytics │    │ • Backups   │         │\n│  │   limiting  │    │             │    │             │         │\n│  └─────────────┘    └─────────────┘    └─────────────┘         │\n│        │                  │                  │                  │\n│        └──────────────────┼──────────────────┘                  │\n│                           │                                      │\n│                    ┌──────▼──────┐                               │\n│                    │ Application │                               │\n│                    │   Servers   │                               │\n│                    └─────────────┘                               │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n### PostgreSQL Schema\n\n```sql\n-- Enable required extensions\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\nCREATE EXTENSION IF NOT EXISTS \"pg_trgm\";  -- For search\nCREATE EXTENSION IF NOT EXISTS \"btree_gist\"; -- For range queries\n\n-- Documents table (sharded by tenant_id for multi-tenant)\nCREATE TABLE documents (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    tenant_id UUID NOT NULL,\n    title TEXT NOT NULL,\n    created_by UUID NOT NULL REFERENCES users(id),\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    updated_at TIMESTAMPTZ DEFAULT NOW(),\n    deleted_at TIMESTAMPTZ,\n    \n    -- CRDT metadata\n    crdt_clock BIGINT DEFAULT 0,\n    last_snapshot_at TIMESTAMPTZ,\n    snapshot_url TEXT,\n    \n    -- Access control\n    visibility TEXT DEFAULT 'private' CHECK (visibility IN ('private', 'team', 'public')),\n    \n    -- Search\n    search_vector TSVECTOR,\n    \n    -- Indexes\n    CONSTRAINT documents_tenant_idx UNIQUE (tenant_id, id)\n);\n\n-- Partition by tenant for large deployments\n-- CREATE TABLE documents PARTITION BY HASH (tenant_id);\n\n-- Version history (append-only)\nCREATE TABLE document_versions (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    document_id UUID NOT NULL REFERENCES documents(id),\n    version_number INTEGER NOT NULL,\n    \n    -- Snapshot data\n    snapshot_url TEXT NOT NULL,  -- S3 URL\n    snapshot_size_bytes BIGINT,\n    \n    -- Metadata\n    created_by UUID REFERENCES users(id),\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    title TEXT,\n    description TEXT,\n    \n    -- For incremental snapshots\n    base_version_id UUID REFERENCES document_versions(id),\n    delta_operations JSONB,  -- Operations since base version\n    \n    CONSTRAINT unique_doc_version UNIQUE (document_id, version_number)\n);\n\n-- Create index for version queries\nCREATE INDEX idx_versions_document_created \nON document_versions (document_id, created_at DESC);\n\n-- Operations log (for audit and replay)\nCREATE TABLE operations_log (\n    id BIGSERIAL,  -- Use BIGSERIAL for high-throughput\n    document_id UUID NOT NULL,\n    user_id UUID NOT NULL,\n    \n    -- Operation data\n    operation_type TEXT NOT NULL,\n    operation_data JSONB NOT NULL,\n    client_timestamp TIMESTAMPTZ NOT NULL,\n    server_timestamp TIMESTAMPTZ DEFAULT NOW(),\n    \n    -- CRDT vector clock\n    vector_clock JSONB NOT NULL,\n    \n    -- Partitioning key\n    created_date DATE DEFAULT CURRENT_DATE\n) PARTITION BY RANGE (created_date);\n\n-- Create partitions for operations log (daily)\nCREATE TABLE operations_log_default PARTITION OF operations_log DEFAULT;\n\n-- Function to create daily partitions\nCREATE OR REPLACE FUNCTION create_operations_partition()\nRETURNS void AS $$\nDECLARE\n    partition_date DATE := CURRENT_DATE + INTERVAL '1 day';\n    partition_name TEXT := 'operations_log_' || TO_CHAR(partition_date, 'YYYY_MM_DD');\nBEGIN\n    EXECUTE format(\n        'CREATE TABLE IF NOT EXISTS %I PARTITION OF operations_log\n         FOR VALUES FROM (%L) TO (%L)',\n        partition_name,\n        partition_date,\n        partition_date + INTERVAL '1 day'\n    );\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Document sharing and permissions\nCREATE TABLE document_permissions (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,\n    \n    -- Who has access\n    user_id UUID REFERENCES users(id),\n    team_id UUID REFERENCES teams(id),\n    \n    -- Permission level\n    permission TEXT NOT NULL CHECK (permission IN ('view', 'comment', 'edit', 'admin')),\n    \n    -- Metadata\n    granted_by UUID REFERENCES users(id),\n    granted_at TIMESTAMPTZ DEFAULT NOW(),\n    expires_at TIMESTAMPTZ,\n    \n    -- Ensure either user_id or team_id is set\n    CONSTRAINT user_or_team CHECK (\n        (user_id IS NOT NULL AND team_id IS NULL) OR\n        (user_id IS NULL AND team_id IS NOT NULL)\n    )\n);\n\n-- Index for permission lookups\nCREATE INDEX idx_permissions_document ON document_permissions(document_id);\nCREATE INDEX idx_permissions_user ON document_permissions(user_id) WHERE user_id IS NOT NULL;\nCREATE INDEX idx_permissions_team ON document_permissions(team_id) WHERE team_id IS NOT NULL;\n```\n\n### Redis Data Structures\n\n```typescript\n// Redis schema for real-time data\nclass RedisCollaborationStore {\n  private redis: Redis.Cluster;\n  \n  constructor() {\n    this.redis = new Redis.Cluster([\n      { host: 'redis-1.example.com', port: 6379 },\n      { host: 'redis-2.example.com', port: 6379 },\n      { host: 'redis-3.example.com', port: 6379 },\n    ], {\n      redisOptions: {\n        password: process.env.REDIS_PASSWORD,\n        tls: {}\n      },\n      scaleReads: 'slave'\n    });\n  }\n  \n  // Store live CRDT state\n  async setDocumentState(documentId: string, state: Uint8Array): Promise<void> {\n    const key = `doc:${documentId}:state`;\n    await this.redis.setex(key, 3600, Buffer.from(state)); // 1 hour TTL\n  }\n  \n  // Get live CRDT state\n  async getDocumentState(documentId: string): Promise<Uint8Array | null> {\n    const key = `doc:${documentId}:state`;\n    const data = await this.redis.getBuffer(key);\n    return data ? new Uint8Array(data) : null;\n  }\n  \n  // Store user presence\n  async setUserPresence(\n    documentId: string,\n    userId: string,\n    presence: UserPresence\n  ): Promise<void> {\n    const key = `doc:${documentId}:presence`;\n    await this.redis.hset(key, userId, JSON.stringify(presence));\n    await this.redis.expire(key, 300); // 5 minute TTL\n  }\n  \n  // Get all users in document\n  async getDocumentPresence(documentId: string): Promise<Map<string, UserPresence>> {\n    const key = `doc:${documentId}:presence`;\n    const data = await this.redis.hgetall(key);\n    \n    const presence = new Map<string, UserPresence>();\n    for (const [userId, json] of Object.entries(data)) {\n      presence.set(userId, JSON.parse(json));\n    }\n    return presence;\n  }\n  \n  // Store cursor positions\n  async updateCursor(\n    documentId: string,\n    userId: string,\n    cursor: CursorPosition\n  ): Promise<void> {\n    const key = `doc:${documentId}:cursors`;\n    await this.redis.hset(key, userId, JSON.stringify({\n      ...cursor,\n      timestamp: Date.now()\n    }));\n    \n    // Publish cursor update for real-time sync\n    await this.redis.publish(`doc:${documentId}:cursor-updates`, JSON.stringify({\n      userId,\n      cursor\n    }));\n  }\n  \n  // Rate limiting for operations\n  async checkRateLimit(\n    documentId: string,\n    userId: string,\n    limit: number = 100,\n    windowSeconds: number = 1\n  ): Promise<boolean> {\n    const key = `ratelimit:${documentId}:${userId}`;\n    const current = await this.redis.incr(key);\n    \n    if (current === 1) {\n      await this.redis.expire(key, windowSeconds);\n    }\n    \n    return current <= limit;\n  }\n  \n  // Distributed lock for snapshot creation\n  async acquireSnapshotLock(documentId: string): Promise<boolean> {\n    const key = `lock:snapshot:${documentId}`;\n    const result = await this.redis.set(key, '1', 'EX', 60, 'NX');\n    return result === 'OK';\n  }\n  \n  async releaseSnapshotLock(documentId: string): Promise<void> {\n    const key = `lock:snapshot:${documentId}`;\n    await this.redis.del(key);\n  }\n}\n```\n\n### S3 Storage for Snapshots\n\n```typescript\n// S3 storage for document snapshots\nimport { S3Client, PutObjectCommand, GetObjectCommand } from '@aws-sdk/client-s3';\nimport { getSignedUrl } from '@aws-sdk/s3-request-presigner';\n\nclass SnapshotStorage {\n  private s3: S3Client;\n  private bucket: string;\n  \n  constructor() {\n    this.s3 = new S3Client({\n      region: process.env.AWS_REGION,\n      credentials: {\n        accessKeyId: process.env.AWS_ACCESS_KEY_ID!,\n        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!\n      }\n    });\n    this.bucket = process.env.S3_BUCKET!;\n  }\n  \n  // Save document snapshot\n  async saveSnapshot(\n    documentId: string,\n    versionId: string,\n    state: Uint8Array,\n    metadata: SnapshotMetadata\n  ): Promise<string> {\n    const key = `snapshots/${documentId}/${versionId}.yjs`;\n    \n    // Compress before upload\n    const compressed = await this.compress(state);\n    \n    await this.s3.send(new PutObjectCommand({\n      Bucket: this.bucket,\n      Key: key,\n      Body: compressed,\n      ContentType: 'application/octet-stream',\n      ContentEncoding: 'gzip',\n      Metadata: {\n        'x-document-id': documentId,\n        'x-version-id': versionId,\n        'x-created-by': metadata.createdBy,\n        'x-original-size': state.length.toString()\n      }\n    }));\n    \n    return `s3://${this.bucket}/${key}`;\n  }\n  \n  // Load document snapshot\n  async loadSnapshot(documentId: string, versionId: string): Promise<Uint8Array> {\n    const key = `snapshots/${documentId}/${versionId}.yjs`;\n    \n    const response = await this.s3.send(new GetObjectCommand({\n      Bucket: this.bucket,\n      Key: key\n    }));\n    \n    const compressed = await response.Body!.transformToByteArray();\n    return this.decompress(compressed);\n  }\n  \n  // Get presigned URL for direct client download\n  async getPresignedUrl(documentId: string, versionId: string): Promise<string> {\n    const key = `snapshots/${documentId}/${versionId}.yjs`;\n    \n    const command = new GetObjectCommand({\n      Bucket: this.bucket,\n      Key: key\n    });\n    \n    return getSignedUrl(this.s3, command, { expiresIn: 3600 });\n  }\n  \n  // Incremental snapshot (delta from base)\n  async saveDeltaSnapshot(\n    documentId: string,\n    versionId: string,\n    baseVersionId: string,\n    delta: Uint8Array\n  ): Promise<string> {\n    const key = `snapshots/${documentId}/${versionId}.delta`;\n    \n    await this.s3.send(new PutObjectCommand({\n      Bucket: this.bucket,\n      Key: key,\n      Body: delta,\n      ContentType: 'application/octet-stream',\n      Metadata: {\n        'x-base-version': baseVersionId,\n        'x-type': 'delta'\n      }\n    }));\n    \n    return `s3://${this.bucket}/${key}`;\n  }\n  \n  private async compress(data: Uint8Array): Promise<Buffer> {\n    return new Promise((resolve, reject) => {\n      zlib.gzip(data, (err, result) => {\n        if (err) reject(err);\n        else resolve(result);\n      });\n    });\n  }\n  \n  private async decompress(data: Uint8Array): Promise<Uint8Array> {\n    return new Promise((resolve, reject) => {\n      zlib.gunzip(data, (err, result) => {\n        if (err) reject(err);\n        else resolve(new Uint8Array(result));\n      });\n    });\n  }\n}\n```\n\n---\n\n## 4. Message Queue Selection\n\n### Recommendation: Apache Kafka\n\n```\n┌─────────────────┬────────────┬────────────┬────────────┬────────────┐\n│ Feature         │ Kafka      │ RabbitMQ   │ Redis      │ Pulsar     │\n│                 │            │            │ Streams    │            │\n├─────────────────┼────────────┼────────────┼────────────┼────────────┤\n│ Throughput      │ 1M+ msg/s  │ 50K msg/s  │ 500K msg/s │ 1M+ msg/s  │\n│ Latency         │ 5-10ms     │ 1-5ms      │ <1ms       │ 5-10ms     │\n│ Persistence     │ Excellent  │ Good       │ Good       │ Excellent  │\n│ Ordering        │ Partition  │ Queue      │ Stream     │ Partition  │\n│ Replay          │ Excellent  │ Limited    │ Good       │ Excellent  │\n│ Multi-region    │ Excellent  │ Complex    │ Limited    │ Excellent  │\n│ Complexity      │ High       │ Low        │ Low        │ High       │\n└─────────────────┴────────────┴────────────┴────────────┴────────────┘\n```\n\n### Kafka Implementation\n\n```typescript\n// Kafka configuration and producers/consumers\nimport { Kafka, Producer, Consumer, Partitioners } from 'kafkajs';\n\nclass OperationQueue {\n  private kafka: Kafka;\n  private producer: Producer;\n  private consumers: Map<string, Consumer> = new Map();\n  \n  constructor() {\n    this.kafka = new Kafka({\n      clientId: 'collab-platform',\n      brokers: [\n        'kafka-1.example.com:9092',\n        'kafka-2.example.com:9092',\n        'kafka-3.example.com:9092'\n      ],\n      ssl: true,\n      sasl: {\n        mechanism: 'scram-sha-512',\n        username: process.env.KAFKA_USERNAME!,\n        password: process.env.KAFKA_PASSWORD!\n      }\n    });\n    \n    this.producer = this.kafka.producer({\n      createPartitioner: Partitioners.DefaultPartitioner,\n      idempotent: true,  // Exactly-once semantics\n      transactionalId: 'collab-producer'\n    });\n  }\n  \n  async initialize(): Promise<void> {\n    await this.producer.connect();\n    await this.createTopics();\n  }\n  \n  private async createTopics(): Promise<void> {\n    const admin = this.kafka.admin();\n    await admin.connect();\n    \n    await admin.createTopics({\n      topics: [\n        {\n          topic: 'document-operations',\n          numPartitions: 100,  // High parallelism\n          replicationFactor: 3,\n          configEntries: [\n            { name: 'retention.ms', value: '604800000' },  // 7 days\n            { name: 'cleanup.policy', value: 'delete' }\n          ]\n        },\n        {\n          topic: 'document-snapshots',\n          numPartitions: 20,\n          replicationFactor: 3,\n          configEntries: [\n            { name: 'retention.ms', value: '2592000000' },  // 30 days\n            { name: 'cleanup.policy', value: 'compact,delete' }\n          ]\n        },\n        {\n          topic: 'user-activity',\n          numPartitions: 50,\n          replicationFactor: 3\n        },\n        {\n          topic: 'dead-letter-queue',\n          numPartitions: 10,\n          replicationFactor: 3\n        }\n      ]\n    });\n    \n    await admin.disconnect();\n  }\n  \n  // Publish operation with document-based partitioning\n  async publishOperation(\n    documentId: string,\n    operation: Operation\n  ): Promise<void> {\n    await this.producer.send({\n      topic: 'document-operations',\n      messages: [{\n        key: documentId,  // Ensures ordering per document\n        value: JSON.stringify(operation),\n        headers: {\n          'document-id': documentId,\n          'user-id': operation.userId,\n          'timestamp': Date.now().toString(),\n          'operation-type': operation.type\n        }\n      }]\n    });\n  }\n  \n  // Batch publish for high throughput\n  async publishOperationBatch(\n    operations: Array<{ documentId: string; operation: Operation }>\n  ): Promise<void> {\n    const messages = operations.map(({ documentId, operation }) => ({\n      key: documentId,\n      value: JSON.stringify(operation),\n      headers: {\n        'document-id': documentId,\n        'timestamp': Date.now().toString()\n      }\n    }));\n    \n    await this.producer.send({\n      topic: 'document-operations',\n      messages\n    });\n  }\n  \n  // Create consumer for processing operations\n  async createOperationConsumer(\n    groupId: string,\n    handler: (operation: Operation) => Promise<void>\n  ): Promise<void> {\n    const consumer = this.kafka.consumer({\n      groupId,\n      maxBytesPerPartition: 1048576,  // 1MB\n      sessionTimeout: 30000,\n      heartbeatInterval: 3000\n    });\n    \n    await consumer.connect();\n    await consumer.subscribe({\n      topic: 'document-operations',\n      fromBeginning: false\n    });\n    \n    await consumer.run({\n      eachBatchAutoResolve: false,\n      eachBatch: async ({ batch, resolveOffset, heartbeat }) => {\n        for (const message of batch.messages) {\n          try {\n            const operation = JSON.parse(message.value!.toString());\n            await handler(operation);\n            resolveOffset(message.offset);\n          } catch (error) {\n            // Send to dead letter queue\n            await this.sendToDeadLetter(message, error);\n            resolveOffset(message.offset);\n          }\n          \n          await heartbeat();\n        }\n      }\n    });\n    \n    this.consumers.set(groupId, consumer);\n  }\n  \n  private async sendToDeadLetter(message: any, error: any): Promise<void> {\n    await this.producer.send({\n      topic: 'dead-letter-queue',\n      messages: [{\n        key: message.key,\n        value: message.value,\n        headers: {\n          ...message.headers,\n          'error-message': error.message,\n          'error-stack': error.stack,\n          'original-topic': 'document-operations'\n        }\n      }]\n    });\n  }\n}\n```\n\n---\n\n## 5. Complete System Architecture\n\n```\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                         Multi-Region Architecture                            │\n├─────────────────────────────────────────────────────────────────────────────┤\n│                                                                              │\n│  US-EAST-1                           US-WEST-2                               │\n│  ┌─────────────────────────┐        ┌─────────────────────────┐             │\n│  │     Load Balancer       │        │     Load Balancer       │             │\n│  │     (AWS ALB/NLB)       │        │     (AWS ALB/NLB)       │             │\n│  └───────────┬─────────────┘        └───────────┬─────────────┘             │\n│              │                                   │                           │\n│  ┌───────────▼─────────────┐        ┌───────────▼─────────────┐             │\n│  │   WebSocket Servers     │◄──────►│   WebSocket Servers     │             │\n│  │   (uWebSockets.js)      │  Kafka │   (uWebSockets.js)      │             │\n│  │   Auto-scaling group    │        │   Auto-scaling group    │             │\n│  └───────────┬─────────────┘        └───────────┬─────────────┘             │\n│              │                                   │                           │\n│  ┌───────────▼─────────────┐        ┌───────────▼─────────────┐             │\n│  │     Redis Cluster       │◄──────►│     Redis Cluster       │             │\n│  │   (Active-Active)       │  CRDT  │   (Active-Active)       │             │\n│  └───────────┬─────────────┘  Sync  └───────────┬─────────────┘             │\n│              │                                   │                           │\n│  ┌───────────▼─────────────┐        ┌───────────▼─────────────┐             │\n│  │   PostgreSQL (Citus)    │◄──────►│   PostgreSQL (Citus)    │             │\n│  │   Primary + Replicas    │ Logical│   Primary + Replicas    │             │\n│  └───────────┬─────────────┘  Repl  └───────────┬─────────────┘             │\n│              │                                   │                           │\n│  ┌───────────▼─────────────┐        ┌───────────▼─────────────┐             │\n│  │     Kafka Cluster       │◄──────►│     Kafka Cluster       │             │\n│  │   (MirrorMaker 2)       │ Mirror │   (MirrorMaker 2)       │             │\n│  └─────────────────────────┘        └─────────────────────────┘             │\n│                                                                              │\n│                          ┌─────────────────────┐                             │\n│                          │    S3 (Global)      │                             │\n│                          │  Cross-region repl  │                             │\n│                          └─────────────────────┘                             │\n│                                                                              │\n│                          ┌─────────────────────┐                             │\n│                          │   Global DNS        │                             │\n│                          │  (Route 53/CF)      │                             │\n│                          └─────────────────────┘                             │\n└─────────────────────────────────────────────────────────────────────────────┘\n```\n\n### Service Implementation\n\n```typescript\n// Main collaboration service\nclass CollaborationService {\n  private wsServers: Map<string, WebSocketServer> = new Map();\n  private documentManager: DocumentManager;\n  private operationQueue: OperationQueue;\n  private snapshotStorage: SnapshotStorage;\n  private redisStore: RedisCollaborationStore;\n  private metrics: MetricsCollector;\n  \n  constructor(private config: ServiceConfig) {\n    this.documentManager = new DocumentManager();\n    this.operationQueue = new OperationQueue();\n    this.snapshotStorage = new SnapshotStorage();\n    this.redisStore = new RedisCollaborationStore();\n    this.metrics = new MetricsCollector();\n  }\n  \n  async start(): Promise<void> {\n    // Initialize all components\n    await Promise.all([\n      this.operationQueue.initialize(),\n      this.documentManager.initialize(),\n    ]);\n    \n    // Start WebSocket servers\n    await this.startWebSocketServers();\n    \n    // Start background workers\n    this.startSnapshotWorker();\n    this.startCleanupWorker();\n    this.startMetricsCollector();\n    \n    console.log('Collaboration service started');\n  }\n  \n  private async startWebSocketServers(): Promise<void> {\n    const serverCount = this.config.wsServerCount || 4;\n    \n    for (let i = 0; i < serverCount; i++) {\n      const port = this.config.basePort + i;\n      const server = new WebSocketServer(port, this);\n      await server.start();\n      this.wsServers.set(`server-${i}`, server);\n    }\n  }\n  \n  // Handle incoming operation from WebSocket\n  async handleOperation(\n    documentId: string,\n    userId: string,\n    operation: Operation\n  ): Promise<OperationResult> {\n    const startTime = performance.now();\n    \n    try {\n      // 1. Rate limiting\n      const allowed = await this.redisStore.checkRateLimit(documentId, userId);\n      if (!allowed) {\n        return { success: false, error: 'Rate limit exceeded' };\n      }\n      \n      // 2. Validate operation\n      const validation = await this.validateOperation(documentId, operation);\n      if (!validation.valid) {\n        return { success: false, error: validation.error };\n      }\n      \n      // 3. Apply to local CRDT state\n      await this.documentManager.applyOperation(documentId, operation);\n      \n      // 4. Update Redis state\n      const state = await this.documentManager.getState(documentId);\n      await this.redisStore.setDocumentState(documentId, state);\n      \n      // 5. Queue for persistence\n      await this.operationQueue.publishOperation(documentId, operation);\n      \n      // 6. Record metrics\n      const latency = performance.now() - startTime;\n      this.metrics.recordLatency('operation_handling', latency);\n      \n      return { success: true, latency };\n    } catch (error) {\n      this.metrics.recordError('operation_handling', error);\n      return { success: false, error: error.message };\n    }\n  }\n  \n  // Periodic snapshot worker\n  private startSnapshotWorker(): void {\n    setInterval(async () => {\n      const activeDocuments = await this.getActiveDocuments();\n      \n      for (const documentId of activeDocuments) {\n        try {\n          // Check if snapshot needed\n          const needsSnapshot = await this.checkSnapshotNeeded(documentId);\n          if (!needsSnapshot) continue;\n          \n          // Acquire lock\n          const locked = await this.redisStore.acquireSnapshotLock(documentId);\n          if (!locked) continue;\n          \n          try {\n            // Create snapshot\n            await this.createSnapshot(documentId);\n          } finally {\n            await this.redisStore.releaseSnapshotLock(documentId);\n          }\n        } catch (error) {\n          console.error(`Snapshot failed for ${documentId}:`, error);\n        }\n      }\n    }, 60000); // Every minute\n  }\n  \n  private async createSnapshot(documentId: string): Promise<void> {\n    const state = await this.documentManager.getState(documentId);\n    const versionId = generateId();\n    \n    // Save to S3\n    const url = await this.snapshotStorage.saveSnapshot(\n      documentId,\n      versionId,\n      state,\n      { createdBy: 'system', createdAt: new Date() }\n    );\n    \n    // Update database\n    await this.db.query(`\n      INSERT INTO document_versions (document_id, version_number, snapshot_url)\n      SELECT $1, COALESCE(MAX(version_number), 0) + 1, $2\n      FROM document_versions WHERE document_id = $1\n    `, [documentId, url]);\n    \n    // Update document metadata\n    await this.db.query(`\n      UPDATE documents \n      SET last_snapshot_at = NOW(), snapshot_url = $2\n      WHERE id = $1\n    `, [documentId, url]);\n  }\n}\n```\n\n---\n\n## 6. Offline Support Implementation\n\n```typescript\n// Client-side offline support\nclass OfflineManager {\n  private db: IDBDatabase;\n  private pendingOperations: Operation[] = [];\n  private isOnline: boolean = navigator.onLine;\n  \n  constructor(private documentId: string) {\n    this.initializeIndexedDB();\n    this.setupNetworkListeners();\n  }\n  \n  private async initializeIndexedDB(): Promise<void> {\n    return new Promise((resolve, reject) => {\n      const request = indexedDB.open('collaboration-offline', 2);\n      \n      request.onupgradeneeded = (event) => {\n        const db = (event.target as IDBOpenDBRequest).result;\n        \n        // Store for document states\n        if (!db.objectStoreNames.contains('documents')) {\n          const docStore = db.createObjectStore('documents', { keyPath: 'id' });\n          docStore.createIndex('updatedAt', 'updatedAt');\n        }\n        \n        // Store for pending operations\n        if (!db.objectStoreNames.contains('pendingOperations')) {\n          const opStore = db.createObjectStore('pendingOperations', { \n            keyPath: 'id', \n            autoIncrement: true \n          });\n          opStore.createIndex('documentId', 'documentId');\n          opStore.createIndex('timestamp', 'timestamp');\n        }\n      };\n      \n      request.onsuccess = (event) => {\n        this.db = (event.target as IDBOpenDBRequest).result;\n        resolve();\n      };\n      \n      request.onerror = reject;\n    });\n  }\n  \n  private setupNetworkListeners(): void {\n    window.addEventListener('online', () => {\n      this.isOnline = true;\n      this.syncPendingOperations();\n    });\n    \n    window.addEventListener('offline', () => {\n      this.isOnline = false;\n    });\n  }\n  \n  // Save document state locally\n  async saveLocalState(state: Uint8Array): Promise<void> {\n    const transaction = this.db.transaction(['documents'], 'readwrite');\n    const store = transaction.objectStore('documents');\n    \n    await new Promise<void>((resolve, reject) => {\n      const request = store.put({\n        id: this.documentId,\n        state: state,\n        updatedAt: Date.now()\n      });\n      request.onsuccess = () => resolve();\n      request.onerror = reject;\n    });\n  }\n  \n  // Load local state\n  async loadLocalState(): Promise<Uint8Array | null> {\n    const transaction = this.db.transaction(['documents'], 'readonly');\n    const store = transaction.objectStore('documents');\n    \n    return new Promise((resolve, reject) => {\n      const request = store.get(this.documentId);\n      request.onsuccess = () => {\n        resolve(request.result?.state || null);\n      };\n      request.onerror = reject;\n    });\n  }\n  \n  // Queue operation for sync\n  async queueOperation(operation: Operation): Promise<void> {\n    const transaction = this.db.transaction(['pendingOperations'], 'readwrite');\n    const store = transaction.objectStore('pendingOperations');\n    \n    await new Promise<void>((resolve, reject) => {\n      const request = store.add({\n        documentId: this.documentId,\n        operation: operation,\n        timestamp: Date.now()\n      });\n      request.onsuccess = () => resolve();\n      request.onerror = reject;\n    });\n    \n    if (this.isOnline) {\n      this.syncPendingOperations();\n    }\n  }\n  \n  // Sync pending operations when online\n  private async syncPendingOperations(): Promise<void> {\n    const transaction = this.db.transaction(['pendingOperations'], 'readonly');\n    const store = transaction.objectStore('pendingOperations');\n    const index = store.index('documentId');\n    \n    const operations: PendingOperation[] = await new Promise((resolve, reject) => {\n      const request = index.getAll(IDBKeyRange.only(this.documentId));\n      request.onsuccess = () => resolve(request.result);\n      request.onerror = reject;\n    });\n    \n    // Sort by timestamp\n    operations.sort((a, b) => a.timestamp - b.timestamp);\n    \n    // Sync each operation\n    for (const op of operations) {\n      try {\n        await this.syncOperation(op);\n        await this.removeOperation(op.id);\n      } catch (error) {\n        if (error.code === 'CONFLICT') {\n          // Handle conflict\n          await this.handleConflict(op);\n        } else {\n          // Retry later\n          break;\n        }\n      }\n    }\n  }\n  \n  private async handleConflict(operation: PendingOperation): Promise<void> {\n    // With CRDTs, conflicts are automatically resolved\n    // Just mark as synced since the CRDT merge handles it\n    await this.removeOperation(operation.id);\n  }\n}\n```\n\n---\n\n## 7. Performance Optimization\n\n### Connection Pooling and Load Balancing\n\n```typescript\n// Smart connection routing\nclass ConnectionRouter {\n  private servers: ServerInfo[] = [];\n  private healthChecker: HealthChecker;\n  \n  constructor() {\n    this.healthChecker = new HealthChecker();\n    this.startHealthChecks();\n  }\n  \n  // Get optimal server for document\n  async getOptimalServer(documentId: string, userId: string): Promise<string> {\n    // 1. Check if document is already active on a server\n    const existingServer = await this.getDocumentServer(documentId);\n    if (existingServer && this.isServerHealthy(existingServer)) {\n      return existingServer;\n    }\n    \n    // 2. Find server with lowest latency to user's region\n    const userRegion = await this.getUserRegion(userId);\n    const regionalServers = this.servers.filter(s => s.region === userRegion);\n    \n    // 3. Select server with lowest load\n    const healthyServers = regionalServers.filter(s => \n      this.isServerHealthy(s.id) && s.connectionCount < s.maxConnections * 0.8\n    );\n    \n    if (healthyServers.length === 0) {\n      // Fallback to any healthy server\n      return this.selectLeastLoadedServer();\n    }\n    \n    // 4. Use consistent hashing for document affinity\n    const server = this.consistentHash(documentId, healthyServers);\n    return server.endpoint;\n  }\n  \n  private consistentHash(key: string, servers: ServerInfo[]): ServerInfo {\n    const hash = this.hashCode(key);\n    const index = Math.abs(hash) % servers.length;\n    return servers[index];\n  }\n}\n```\n\n### Latency Optimization\n\n```typescript\n// Latency optimization strategies\nclass LatencyOptimizer {\n  // 1. Operation batching\n  private operationBuffer: Operation[] = [];\n  private flushTimer: NodeJS.Timeout | null = null;\n  \n  bufferOperation(operation: Operation): void {\n    this.operationBuffer.push(operation);\n    \n    if (this.operationBuffer.length >= 10) {\n      this.flushOperations();\n    } else if (!this.flushTimer) {\n      this.flushTimer = setTimeout(() => this.flushOperations(), 16); // 60fps\n    }\n  }\n  \n  private flushOperations(): void {\n    if (this.operationBuffer.length === 0) return;\n    \n    const operations = this.operationBuffer;\n    this.operationBuffer = [];\n    \n    if (this.flushTimer) {\n      clearTimeout(this.flushTimer);\n      this.flushTimer = null;\n    }\n    \n    // Send batched operations\n    this.sendBatch(operations);\n  }\n  \n  // 2. Predictive preloading\n  async preloadRelatedDocuments(currentDocId: string): Promise<void> {\n    const relatedDocs = await this.getRelatedDocuments(currentDocId);\n    \n    for (const docId of relatedDocs.slice(0, 5)) {\n      // Preload in background\n      this.prefetchDocument(docId);\n    }\n  }\n  \n  // 3. Delta compression\n  compressOperations(operations: Operation[]): Uint8Array {\n    // Use protocol buffers for efficient serialization\n    const message = OperationBatch.encode({\n      operations: operations.map(op => ({\n        type: op.type,\n        position: op.position,\n        content: op.content,\n        timestamp: op.timestamp\n      }))\n    });\n    \n    return pako.deflate(message.finish());\n  }\n}\n```\n\n---\n\n## 8. Monitoring and Observability\n\n```typescript\n// Comprehensive monitoring\nclass MonitoringService {\n  private prometheus: PrometheusClient;\n  private jaeger: JaegerTracer;\n  \n  constructor() {\n    this.setupMetrics();\n    this.setupTracing();\n  }\n  \n  private setupMetrics(): void {\n    // Connection metrics\n    new Gauge({\n      name: 'collab_active_connections',\n      help: 'Number of active WebSocket connections',\n      labelNames: ['region', 'server']\n    });\n    \n    // Document metrics\n    new Gauge({\n      name: 'collab_active_documents',\n      help: 'Number of documents with active editors',\n      labelNames: ['region']\n    });\n    \n    // Latency histograms\n    new Histogram({\n      name: 'collab_operation_latency_ms',\n      help: 'Operation processing latency',\n      labelNames: ['operation_type', 'region'],\n      buckets: [1, 5, 10, 25, 50, 100, 250, 500, 1000]\n    });\n    \n    // Error rates\n    new Counter({\n      name: 'collab_errors_total',\n      help: 'Total number of errors',\n      labelNames: ['error_type', 'region']\n    });\n  }\n  \n  // Health check endpoint\n  async healthCheck(): Promise<HealthStatus> {\n    const checks = await Promise.all([\n      this.checkRedis(),\n      this.checkPostgres(),\n      this.checkKafka(),\n      this.checkS3()\n    ]);\n    \n    return {\n      status: checks.every(c => c.healthy) ? 'healthy' : 'degraded',\n      checks,\n      timestamp: new Date().toISOString()\n    };\n  }\n}\n```\n\n---\n\n## Summary Recommendations\n\n| Component | Recommendation | Rationale |\n|-----------|---------------|-----------|\n| **Transport** | WebSocket + WebRTC hybrid | WebSocket for reliability, WebRTC for P2P latency |\n| **Conflict Resolution** | CRDT (Yjs) | Offline-first, mathematically correct merging |\n| **Primary Database** | PostgreSQL + Citus | ACID compliance, horizontal scaling |\n| **Cache/Real-time** | Redis Cluster | Sub-ms latency, pub/sub support |\n| **Object Storage** | S3 | Durability, cost-effective for snapshots |\n| **Message Queue** | Apache Kafka | Throughput, replay capability, multi-region |\n\n### Key Trade-offs Accepted\n\n1. **Higher memory usage** (CRDTs) for **simpler conflict resolution**\n2. **Infrastructure complexity** for **better latency and reliability**\n3. **Multiple databases** for **optimized access patterns**\n4. **Kafka complexity** for **guaranteed ordering and replay**",
    "tokensIn": 146,
    "tokensOut": 14417,
    "cost": 0.361155,
    "durationMs": 148982,
    "success": true
  }
]